{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data\n",
    "\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "data = df.to_numpy().astype(np.float32)\n",
    "\n",
    "#Shuffle the rows from data so I could take arbitrary rows for test and training.\n",
    "rd.shuffle(data)\n",
    "pivo = round(data.shape[0]*0.66)\n",
    "train_set = data[:pivo,:]\n",
    "test_set = data[pivo:,:]\n",
    "\n",
    "#train data\n",
    "X_train = train_set[:,:-1]\n",
    "Y_train = train_set[:,-1:]\n",
    "Xm_train = np.mean(X_train, axis=0)\n",
    "Xs_train = np.std(X_train, axis=0)\n",
    "input = (X_train-Xm_train)/Xs_train\n",
    "\n",
    "#test data\n",
    "X_test = test_set[:,:-1]\n",
    "Y_test = test_set[:,-1:]\n",
    "Xm_test = np.mean(X_test, axis=0)\n",
    "Xs_test = np.std(X_test, axis=0)\n",
    "input_tst = (X_test-Xm_test)/Xs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(X_train.shape[1], 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "#loss and optimizer\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.ASGD(model.parameters(), lr=0.001)\n",
    "\n",
    "#converting data to torch tensors\n",
    "\n",
    "input_tensor = torch.from_numpy(input)\n",
    "targets = torch.from_numpy(Y_train)\n",
    "\n",
    "input_tst_tensor = torch.from_numpy(input_tst)\n",
    "targets_tst = torch.from_numpy(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100000, Train Loss: 0.7539, Test Loss: 0.7264\n",
      "Epoch 100/100000, Train Loss: 0.7463, Test Loss: 0.7204\n",
      "Epoch 150/100000, Train Loss: 0.7390, Test Loss: 0.7147\n",
      "Epoch 200/100000, Train Loss: 0.7319, Test Loss: 0.7092\n",
      "Epoch 250/100000, Train Loss: 0.7250, Test Loss: 0.7039\n",
      "Epoch 300/100000, Train Loss: 0.7184, Test Loss: 0.6987\n",
      "Epoch 350/100000, Train Loss: 0.7120, Test Loss: 0.6938\n",
      "Epoch 400/100000, Train Loss: 0.7059, Test Loss: 0.6890\n",
      "Epoch 450/100000, Train Loss: 0.6999, Test Loss: 0.6844\n",
      "Epoch 500/100000, Train Loss: 0.6941, Test Loss: 0.6800\n",
      "Epoch 550/100000, Train Loss: 0.6885, Test Loss: 0.6757\n",
      "Epoch 600/100000, Train Loss: 0.6831, Test Loss: 0.6716\n",
      "Epoch 650/100000, Train Loss: 0.6779, Test Loss: 0.6676\n",
      "Epoch 700/100000, Train Loss: 0.6728, Test Loss: 0.6638\n",
      "Epoch 750/100000, Train Loss: 0.6679, Test Loss: 0.6600\n",
      "Epoch 800/100000, Train Loss: 0.6632, Test Loss: 0.6565\n",
      "Epoch 850/100000, Train Loss: 0.6586, Test Loss: 0.6530\n",
      "Epoch 900/100000, Train Loss: 0.6541, Test Loss: 0.6497\n",
      "Epoch 950/100000, Train Loss: 0.6498, Test Loss: 0.6464\n",
      "Epoch 1000/100000, Train Loss: 0.6456, Test Loss: 0.6433\n",
      "Epoch 1050/100000, Train Loss: 0.6416, Test Loss: 0.6403\n",
      "Epoch 1100/100000, Train Loss: 0.6376, Test Loss: 0.6374\n",
      "Epoch 1150/100000, Train Loss: 0.6338, Test Loss: 0.6345\n",
      "Epoch 1200/100000, Train Loss: 0.6301, Test Loss: 0.6318\n",
      "Epoch 1250/100000, Train Loss: 0.6265, Test Loss: 0.6291\n",
      "Epoch 1300/100000, Train Loss: 0.6230, Test Loss: 0.6266\n",
      "Epoch 1350/100000, Train Loss: 0.6196, Test Loss: 0.6241\n",
      "Epoch 1400/100000, Train Loss: 0.6163, Test Loss: 0.6217\n",
      "Epoch 1450/100000, Train Loss: 0.6131, Test Loss: 0.6193\n",
      "Epoch 1500/100000, Train Loss: 0.6100, Test Loss: 0.6171\n",
      "Epoch 1550/100000, Train Loss: 0.6070, Test Loss: 0.6149\n",
      "Epoch 1600/100000, Train Loss: 0.6040, Test Loss: 0.6128\n",
      "Epoch 1650/100000, Train Loss: 0.6012, Test Loss: 0.6107\n",
      "Epoch 1700/100000, Train Loss: 0.5984, Test Loss: 0.6087\n",
      "Epoch 1750/100000, Train Loss: 0.5956, Test Loss: 0.6067\n",
      "Epoch 1800/100000, Train Loss: 0.5930, Test Loss: 0.6049\n",
      "Epoch 1850/100000, Train Loss: 0.5904, Test Loss: 0.6030\n",
      "Epoch 1900/100000, Train Loss: 0.5879, Test Loss: 0.6012\n",
      "Epoch 1950/100000, Train Loss: 0.5855, Test Loss: 0.5995\n",
      "Epoch 2000/100000, Train Loss: 0.5831, Test Loss: 0.5978\n",
      "Epoch 2050/100000, Train Loss: 0.5808, Test Loss: 0.5962\n",
      "Epoch 2100/100000, Train Loss: 0.5785, Test Loss: 0.5946\n",
      "Epoch 2150/100000, Train Loss: 0.5763, Test Loss: 0.5930\n",
      "Epoch 2200/100000, Train Loss: 0.5742, Test Loss: 0.5915\n",
      "Epoch 2250/100000, Train Loss: 0.5721, Test Loss: 0.5901\n",
      "Epoch 2300/100000, Train Loss: 0.5700, Test Loss: 0.5886\n",
      "Epoch 2350/100000, Train Loss: 0.5680, Test Loss: 0.5872\n",
      "Epoch 2400/100000, Train Loss: 0.5661, Test Loss: 0.5859\n",
      "Epoch 2450/100000, Train Loss: 0.5642, Test Loss: 0.5846\n",
      "Epoch 2500/100000, Train Loss: 0.5623, Test Loss: 0.5833\n",
      "Epoch 2550/100000, Train Loss: 0.5605, Test Loss: 0.5820\n",
      "Epoch 2600/100000, Train Loss: 0.5587, Test Loss: 0.5808\n",
      "Epoch 2650/100000, Train Loss: 0.5570, Test Loss: 0.5796\n",
      "Epoch 2700/100000, Train Loss: 0.5553, Test Loss: 0.5785\n",
      "Epoch 2750/100000, Train Loss: 0.5536, Test Loss: 0.5773\n",
      "Epoch 2800/100000, Train Loss: 0.5520, Test Loss: 0.5762\n",
      "Epoch 2850/100000, Train Loss: 0.5504, Test Loss: 0.5751\n",
      "Epoch 2900/100000, Train Loss: 0.5488, Test Loss: 0.5741\n",
      "Epoch 2950/100000, Train Loss: 0.5473, Test Loss: 0.5731\n",
      "Epoch 3000/100000, Train Loss: 0.5458, Test Loss: 0.5721\n",
      "Epoch 3050/100000, Train Loss: 0.5444, Test Loss: 0.5711\n",
      "Epoch 3100/100000, Train Loss: 0.5430, Test Loss: 0.5701\n",
      "Epoch 3150/100000, Train Loss: 0.5416, Test Loss: 0.5692\n",
      "Epoch 3200/100000, Train Loss: 0.5402, Test Loss: 0.5683\n",
      "Epoch 3250/100000, Train Loss: 0.5389, Test Loss: 0.5674\n",
      "Epoch 3300/100000, Train Loss: 0.5376, Test Loss: 0.5665\n",
      "Epoch 3350/100000, Train Loss: 0.5363, Test Loss: 0.5657\n",
      "Epoch 3400/100000, Train Loss: 0.5350, Test Loss: 0.5648\n",
      "Epoch 3450/100000, Train Loss: 0.5338, Test Loss: 0.5640\n",
      "Epoch 3500/100000, Train Loss: 0.5326, Test Loss: 0.5632\n",
      "Epoch 3550/100000, Train Loss: 0.5314, Test Loss: 0.5625\n",
      "Epoch 3600/100000, Train Loss: 0.5302, Test Loss: 0.5617\n",
      "Epoch 3650/100000, Train Loss: 0.5291, Test Loss: 0.5609\n",
      "Epoch 3700/100000, Train Loss: 0.5280, Test Loss: 0.5602\n",
      "Epoch 3750/100000, Train Loss: 0.5269, Test Loss: 0.5595\n",
      "Epoch 3800/100000, Train Loss: 0.5258, Test Loss: 0.5588\n",
      "Epoch 3850/100000, Train Loss: 0.5248, Test Loss: 0.5581\n",
      "Epoch 3900/100000, Train Loss: 0.5237, Test Loss: 0.5575\n",
      "Epoch 3950/100000, Train Loss: 0.5227, Test Loss: 0.5568\n",
      "Epoch 4000/100000, Train Loss: 0.5217, Test Loss: 0.5562\n",
      "Epoch 4050/100000, Train Loss: 0.5208, Test Loss: 0.5555\n",
      "Epoch 4100/100000, Train Loss: 0.5198, Test Loss: 0.5549\n",
      "Epoch 4150/100000, Train Loss: 0.5189, Test Loss: 0.5543\n",
      "Epoch 4200/100000, Train Loss: 0.5179, Test Loss: 0.5537\n",
      "Epoch 4250/100000, Train Loss: 0.5170, Test Loss: 0.5532\n",
      "Epoch 4300/100000, Train Loss: 0.5161, Test Loss: 0.5526\n",
      "Epoch 4350/100000, Train Loss: 0.5153, Test Loss: 0.5520\n",
      "Epoch 4400/100000, Train Loss: 0.5144, Test Loss: 0.5515\n",
      "Epoch 4450/100000, Train Loss: 0.5136, Test Loss: 0.5510\n",
      "Epoch 4500/100000, Train Loss: 0.5127, Test Loss: 0.5504\n",
      "Epoch 4550/100000, Train Loss: 0.5119, Test Loss: 0.5499\n",
      "Epoch 4600/100000, Train Loss: 0.5111, Test Loss: 0.5494\n",
      "Epoch 4650/100000, Train Loss: 0.5103, Test Loss: 0.5489\n",
      "Epoch 4700/100000, Train Loss: 0.5096, Test Loss: 0.5484\n",
      "Epoch 4750/100000, Train Loss: 0.5088, Test Loss: 0.5480\n",
      "Epoch 4800/100000, Train Loss: 0.5081, Test Loss: 0.5475\n",
      "Epoch 4850/100000, Train Loss: 0.5073, Test Loss: 0.5471\n",
      "Epoch 4900/100000, Train Loss: 0.5066, Test Loss: 0.5466\n",
      "Epoch 4950/100000, Train Loss: 0.5059, Test Loss: 0.5462\n",
      "Epoch 5000/100000, Train Loss: 0.5052, Test Loss: 0.5457\n",
      "Epoch 5050/100000, Train Loss: 0.5045, Test Loss: 0.5453\n",
      "Epoch 5100/100000, Train Loss: 0.5038, Test Loss: 0.5449\n",
      "Epoch 5150/100000, Train Loss: 0.5032, Test Loss: 0.5445\n",
      "Epoch 5200/100000, Train Loss: 0.5025, Test Loss: 0.5441\n",
      "Epoch 5250/100000, Train Loss: 0.5019, Test Loss: 0.5437\n",
      "Epoch 5300/100000, Train Loss: 0.5013, Test Loss: 0.5433\n",
      "Epoch 5350/100000, Train Loss: 0.5006, Test Loss: 0.5429\n",
      "Epoch 5400/100000, Train Loss: 0.5000, Test Loss: 0.5426\n",
      "Epoch 5450/100000, Train Loss: 0.4994, Test Loss: 0.5422\n",
      "Epoch 5500/100000, Train Loss: 0.4988, Test Loss: 0.5419\n",
      "Epoch 5550/100000, Train Loss: 0.4982, Test Loss: 0.5415\n",
      "Epoch 5600/100000, Train Loss: 0.4977, Test Loss: 0.5412\n",
      "Epoch 5650/100000, Train Loss: 0.4971, Test Loss: 0.5408\n",
      "Epoch 5700/100000, Train Loss: 0.4966, Test Loss: 0.5405\n",
      "Epoch 5750/100000, Train Loss: 0.4960, Test Loss: 0.5402\n",
      "Epoch 5800/100000, Train Loss: 0.4955, Test Loss: 0.5398\n",
      "Epoch 5850/100000, Train Loss: 0.4949, Test Loss: 0.5395\n",
      "Epoch 5900/100000, Train Loss: 0.4944, Test Loss: 0.5392\n",
      "Epoch 5950/100000, Train Loss: 0.4939, Test Loss: 0.5389\n",
      "Epoch 6000/100000, Train Loss: 0.4934, Test Loss: 0.5386\n",
      "Epoch 6050/100000, Train Loss: 0.4929, Test Loss: 0.5383\n",
      "Epoch 6100/100000, Train Loss: 0.4924, Test Loss: 0.5380\n",
      "Epoch 6150/100000, Train Loss: 0.4919, Test Loss: 0.5378\n",
      "Epoch 6200/100000, Train Loss: 0.4915, Test Loss: 0.5375\n",
      "Epoch 6250/100000, Train Loss: 0.4910, Test Loss: 0.5372\n",
      "Epoch 6300/100000, Train Loss: 0.4905, Test Loss: 0.5369\n",
      "Epoch 6350/100000, Train Loss: 0.4901, Test Loss: 0.5367\n",
      "Epoch 6400/100000, Train Loss: 0.4896, Test Loss: 0.5364\n",
      "Epoch 6450/100000, Train Loss: 0.4892, Test Loss: 0.5362\n",
      "Epoch 6500/100000, Train Loss: 0.4887, Test Loss: 0.5359\n",
      "Epoch 6550/100000, Train Loss: 0.4883, Test Loss: 0.5357\n",
      "Epoch 6600/100000, Train Loss: 0.4879, Test Loss: 0.5354\n",
      "Epoch 6650/100000, Train Loss: 0.4875, Test Loss: 0.5352\n",
      "Epoch 6700/100000, Train Loss: 0.4871, Test Loss: 0.5349\n",
      "Epoch 6750/100000, Train Loss: 0.4867, Test Loss: 0.5347\n",
      "Epoch 6800/100000, Train Loss: 0.4863, Test Loss: 0.5345\n",
      "Epoch 6850/100000, Train Loss: 0.4859, Test Loss: 0.5343\n",
      "Epoch 6900/100000, Train Loss: 0.4855, Test Loss: 0.5340\n",
      "Epoch 6950/100000, Train Loss: 0.4851, Test Loss: 0.5338\n",
      "Epoch 7000/100000, Train Loss: 0.4847, Test Loss: 0.5336\n",
      "Epoch 7050/100000, Train Loss: 0.4844, Test Loss: 0.5334\n",
      "Epoch 7100/100000, Train Loss: 0.4840, Test Loss: 0.5332\n",
      "Epoch 7150/100000, Train Loss: 0.4836, Test Loss: 0.5330\n",
      "Epoch 7200/100000, Train Loss: 0.4833, Test Loss: 0.5328\n",
      "Epoch 7250/100000, Train Loss: 0.4829, Test Loss: 0.5326\n",
      "Epoch 7300/100000, Train Loss: 0.4826, Test Loss: 0.5324\n",
      "Epoch 7350/100000, Train Loss: 0.4822, Test Loss: 0.5322\n",
      "Epoch 7400/100000, Train Loss: 0.4819, Test Loss: 0.5320\n",
      "Epoch 7450/100000, Train Loss: 0.4816, Test Loss: 0.5319\n",
      "Epoch 7500/100000, Train Loss: 0.4812, Test Loss: 0.5317\n",
      "Epoch 7550/100000, Train Loss: 0.4809, Test Loss: 0.5315\n",
      "Epoch 7600/100000, Train Loss: 0.4806, Test Loss: 0.5313\n",
      "Epoch 7650/100000, Train Loss: 0.4803, Test Loss: 0.5312\n",
      "Epoch 7700/100000, Train Loss: 0.4800, Test Loss: 0.5310\n",
      "Epoch 7750/100000, Train Loss: 0.4797, Test Loss: 0.5308\n",
      "Epoch 7800/100000, Train Loss: 0.4794, Test Loss: 0.5307\n",
      "Epoch 7850/100000, Train Loss: 0.4791, Test Loss: 0.5305\n",
      "Epoch 7900/100000, Train Loss: 0.4788, Test Loss: 0.5303\n",
      "Epoch 7950/100000, Train Loss: 0.4785, Test Loss: 0.5302\n",
      "Epoch 8000/100000, Train Loss: 0.4782, Test Loss: 0.5300\n",
      "Epoch 8050/100000, Train Loss: 0.4779, Test Loss: 0.5299\n",
      "Epoch 8100/100000, Train Loss: 0.4776, Test Loss: 0.5297\n",
      "Epoch 8150/100000, Train Loss: 0.4774, Test Loss: 0.5296\n",
      "Epoch 8200/100000, Train Loss: 0.4771, Test Loss: 0.5294\n",
      "Epoch 8250/100000, Train Loss: 0.4768, Test Loss: 0.5293\n",
      "Epoch 8300/100000, Train Loss: 0.4765, Test Loss: 0.5292\n",
      "Epoch 8350/100000, Train Loss: 0.4763, Test Loss: 0.5290\n",
      "Epoch 8400/100000, Train Loss: 0.4760, Test Loss: 0.5289\n",
      "Epoch 8450/100000, Train Loss: 0.4758, Test Loss: 0.5288\n",
      "Epoch 8500/100000, Train Loss: 0.4755, Test Loss: 0.5286\n",
      "Epoch 8550/100000, Train Loss: 0.4753, Test Loss: 0.5285\n",
      "Epoch 8600/100000, Train Loss: 0.4750, Test Loss: 0.5284\n",
      "Epoch 8650/100000, Train Loss: 0.4748, Test Loss: 0.5282\n",
      "Epoch 8700/100000, Train Loss: 0.4746, Test Loss: 0.5281\n",
      "Epoch 8750/100000, Train Loss: 0.4743, Test Loss: 0.5280\n",
      "Epoch 8800/100000, Train Loss: 0.4741, Test Loss: 0.5279\n",
      "Epoch 8850/100000, Train Loss: 0.4739, Test Loss: 0.5278\n",
      "Epoch 8900/100000, Train Loss: 0.4736, Test Loss: 0.5276\n",
      "Epoch 8950/100000, Train Loss: 0.4734, Test Loss: 0.5275\n",
      "Epoch 9000/100000, Train Loss: 0.4732, Test Loss: 0.5274\n",
      "Epoch 9050/100000, Train Loss: 0.4730, Test Loss: 0.5273\n",
      "Epoch 9100/100000, Train Loss: 0.4727, Test Loss: 0.5272\n",
      "Epoch 9150/100000, Train Loss: 0.4725, Test Loss: 0.5271\n",
      "Epoch 9200/100000, Train Loss: 0.4723, Test Loss: 0.5270\n",
      "Epoch 9250/100000, Train Loss: 0.4721, Test Loss: 0.5269\n",
      "Epoch 9300/100000, Train Loss: 0.4719, Test Loss: 0.5268\n",
      "Epoch 9350/100000, Train Loss: 0.4717, Test Loss: 0.5267\n",
      "Epoch 9400/100000, Train Loss: 0.4715, Test Loss: 0.5266\n",
      "Epoch 9450/100000, Train Loss: 0.4713, Test Loss: 0.5265\n",
      "Epoch 9500/100000, Train Loss: 0.4711, Test Loss: 0.5264\n",
      "Epoch 9550/100000, Train Loss: 0.4709, Test Loss: 0.5263\n",
      "Epoch 9600/100000, Train Loss: 0.4707, Test Loss: 0.5262\n",
      "Epoch 9650/100000, Train Loss: 0.4705, Test Loss: 0.5261\n",
      "Epoch 9700/100000, Train Loss: 0.4704, Test Loss: 0.5260\n",
      "Epoch 9750/100000, Train Loss: 0.4702, Test Loss: 0.5259\n",
      "Epoch 9800/100000, Train Loss: 0.4700, Test Loss: 0.5258\n",
      "Epoch 9850/100000, Train Loss: 0.4698, Test Loss: 0.5258\n",
      "Epoch 9900/100000, Train Loss: 0.4696, Test Loss: 0.5257\n",
      "Epoch 9950/100000, Train Loss: 0.4695, Test Loss: 0.5256\n",
      "Epoch 10000/100000, Train Loss: 0.4693, Test Loss: 0.5255\n",
      "Epoch 10050/100000, Train Loss: 0.4691, Test Loss: 0.5254\n",
      "Epoch 10100/100000, Train Loss: 0.4689, Test Loss: 0.5253\n",
      "Epoch 10150/100000, Train Loss: 0.4688, Test Loss: 0.5253\n",
      "Epoch 10200/100000, Train Loss: 0.4686, Test Loss: 0.5252\n",
      "Epoch 10250/100000, Train Loss: 0.4685, Test Loss: 0.5251\n",
      "Epoch 10300/100000, Train Loss: 0.4683, Test Loss: 0.5250\n",
      "Epoch 10350/100000, Train Loss: 0.4681, Test Loss: 0.5250\n",
      "Epoch 10400/100000, Train Loss: 0.4680, Test Loss: 0.5249\n",
      "Epoch 10450/100000, Train Loss: 0.4678, Test Loss: 0.5248\n",
      "Epoch 10500/100000, Train Loss: 0.4677, Test Loss: 0.5247\n",
      "Epoch 10550/100000, Train Loss: 0.4675, Test Loss: 0.5247\n",
      "Epoch 10600/100000, Train Loss: 0.4674, Test Loss: 0.5246\n",
      "Epoch 10650/100000, Train Loss: 0.4672, Test Loss: 0.5245\n",
      "Epoch 10700/100000, Train Loss: 0.4671, Test Loss: 0.5245\n",
      "Epoch 10750/100000, Train Loss: 0.4669, Test Loss: 0.5244\n",
      "Epoch 10800/100000, Train Loss: 0.4668, Test Loss: 0.5243\n",
      "Epoch 10850/100000, Train Loss: 0.4666, Test Loss: 0.5243\n",
      "Epoch 10900/100000, Train Loss: 0.4665, Test Loss: 0.5242\n",
      "Epoch 10950/100000, Train Loss: 0.4664, Test Loss: 0.5241\n",
      "Epoch 11000/100000, Train Loss: 0.4662, Test Loss: 0.5241\n",
      "Epoch 11050/100000, Train Loss: 0.4661, Test Loss: 0.5240\n",
      "Epoch 11100/100000, Train Loss: 0.4659, Test Loss: 0.5240\n",
      "Epoch 11150/100000, Train Loss: 0.4658, Test Loss: 0.5239\n",
      "Epoch 11200/100000, Train Loss: 0.4657, Test Loss: 0.5238\n",
      "Epoch 11250/100000, Train Loss: 0.4656, Test Loss: 0.5238\n",
      "Epoch 11300/100000, Train Loss: 0.4654, Test Loss: 0.5237\n",
      "Epoch 11350/100000, Train Loss: 0.4653, Test Loss: 0.5237\n",
      "Epoch 11400/100000, Train Loss: 0.4652, Test Loss: 0.5236\n",
      "Epoch 11450/100000, Train Loss: 0.4650, Test Loss: 0.5236\n",
      "Epoch 11500/100000, Train Loss: 0.4649, Test Loss: 0.5235\n",
      "Epoch 11550/100000, Train Loss: 0.4648, Test Loss: 0.5235\n",
      "Epoch 11600/100000, Train Loss: 0.4647, Test Loss: 0.5234\n",
      "Epoch 11650/100000, Train Loss: 0.4646, Test Loss: 0.5234\n",
      "Epoch 11700/100000, Train Loss: 0.4644, Test Loss: 0.5233\n",
      "Epoch 11750/100000, Train Loss: 0.4643, Test Loss: 0.5233\n",
      "Epoch 11800/100000, Train Loss: 0.4642, Test Loss: 0.5232\n",
      "Epoch 11850/100000, Train Loss: 0.4641, Test Loss: 0.5232\n",
      "Epoch 11900/100000, Train Loss: 0.4640, Test Loss: 0.5231\n",
      "Epoch 11950/100000, Train Loss: 0.4639, Test Loss: 0.5231\n",
      "Epoch 12000/100000, Train Loss: 0.4638, Test Loss: 0.5230\n",
      "Epoch 12050/100000, Train Loss: 0.4637, Test Loss: 0.5230\n",
      "Epoch 12100/100000, Train Loss: 0.4636, Test Loss: 0.5229\n",
      "Epoch 12150/100000, Train Loss: 0.4635, Test Loss: 0.5229\n",
      "Epoch 12200/100000, Train Loss: 0.4633, Test Loss: 0.5229\n",
      "Epoch 12250/100000, Train Loss: 0.4632, Test Loss: 0.5228\n",
      "Epoch 12300/100000, Train Loss: 0.4631, Test Loss: 0.5228\n",
      "Epoch 12350/100000, Train Loss: 0.4630, Test Loss: 0.5227\n",
      "Epoch 12400/100000, Train Loss: 0.4629, Test Loss: 0.5227\n",
      "Epoch 12450/100000, Train Loss: 0.4628, Test Loss: 0.5227\n",
      "Epoch 12500/100000, Train Loss: 0.4627, Test Loss: 0.5226\n",
      "Epoch 12550/100000, Train Loss: 0.4626, Test Loss: 0.5226\n",
      "Epoch 12600/100000, Train Loss: 0.4625, Test Loss: 0.5225\n",
      "Epoch 12650/100000, Train Loss: 0.4624, Test Loss: 0.5225\n",
      "Epoch 12700/100000, Train Loss: 0.4624, Test Loss: 0.5225\n",
      "Epoch 12750/100000, Train Loss: 0.4623, Test Loss: 0.5224\n",
      "Epoch 12800/100000, Train Loss: 0.4622, Test Loss: 0.5224\n",
      "Epoch 12850/100000, Train Loss: 0.4621, Test Loss: 0.5224\n",
      "Epoch 12900/100000, Train Loss: 0.4620, Test Loss: 0.5223\n",
      "Epoch 12950/100000, Train Loss: 0.4619, Test Loss: 0.5223\n",
      "Epoch 13000/100000, Train Loss: 0.4618, Test Loss: 0.5223\n",
      "Epoch 13050/100000, Train Loss: 0.4617, Test Loss: 0.5222\n",
      "Epoch 13100/100000, Train Loss: 0.4616, Test Loss: 0.5222\n",
      "Epoch 13150/100000, Train Loss: 0.4615, Test Loss: 0.5222\n",
      "Epoch 13200/100000, Train Loss: 0.4615, Test Loss: 0.5221\n",
      "Epoch 13250/100000, Train Loss: 0.4614, Test Loss: 0.5221\n",
      "Epoch 13300/100000, Train Loss: 0.4613, Test Loss: 0.5221\n",
      "Epoch 13350/100000, Train Loss: 0.4612, Test Loss: 0.5220\n",
      "Epoch 13400/100000, Train Loss: 0.4611, Test Loss: 0.5220\n",
      "Epoch 13450/100000, Train Loss: 0.4611, Test Loss: 0.5220\n",
      "Epoch 13500/100000, Train Loss: 0.4610, Test Loss: 0.5220\n",
      "Epoch 13550/100000, Train Loss: 0.4609, Test Loss: 0.5219\n",
      "Epoch 13600/100000, Train Loss: 0.4608, Test Loss: 0.5219\n",
      "Epoch 13650/100000, Train Loss: 0.4607, Test Loss: 0.5219\n",
      "Epoch 13700/100000, Train Loss: 0.4607, Test Loss: 0.5218\n",
      "Epoch 13750/100000, Train Loss: 0.4606, Test Loss: 0.5218\n",
      "Epoch 13800/100000, Train Loss: 0.4605, Test Loss: 0.5218\n",
      "Epoch 13850/100000, Train Loss: 0.4604, Test Loss: 0.5218\n",
      "Epoch 13900/100000, Train Loss: 0.4604, Test Loss: 0.5217\n",
      "Epoch 13950/100000, Train Loss: 0.4603, Test Loss: 0.5217\n",
      "Epoch 14000/100000, Train Loss: 0.4602, Test Loss: 0.5217\n",
      "Epoch 14050/100000, Train Loss: 0.4601, Test Loss: 0.5217\n",
      "Epoch 14100/100000, Train Loss: 0.4601, Test Loss: 0.5216\n",
      "Epoch 14150/100000, Train Loss: 0.4600, Test Loss: 0.5216\n",
      "Epoch 14200/100000, Train Loss: 0.4599, Test Loss: 0.5216\n",
      "Epoch 14250/100000, Train Loss: 0.4599, Test Loss: 0.5216\n",
      "Epoch 14300/100000, Train Loss: 0.4598, Test Loss: 0.5216\n",
      "Epoch 14350/100000, Train Loss: 0.4597, Test Loss: 0.5215\n",
      "Epoch 14400/100000, Train Loss: 0.4597, Test Loss: 0.5215\n",
      "Epoch 14450/100000, Train Loss: 0.4596, Test Loss: 0.5215\n",
      "Epoch 14500/100000, Train Loss: 0.4595, Test Loss: 0.5215\n",
      "Epoch 14550/100000, Train Loss: 0.4595, Test Loss: 0.5214\n",
      "Epoch 14600/100000, Train Loss: 0.4594, Test Loss: 0.5214\n",
      "Epoch 14650/100000, Train Loss: 0.4593, Test Loss: 0.5214\n",
      "Epoch 14700/100000, Train Loss: 0.4593, Test Loss: 0.5214\n",
      "Epoch 14750/100000, Train Loss: 0.4592, Test Loss: 0.5214\n",
      "Epoch 14800/100000, Train Loss: 0.4592, Test Loss: 0.5213\n",
      "Epoch 14850/100000, Train Loss: 0.4591, Test Loss: 0.5213\n",
      "Epoch 14900/100000, Train Loss: 0.4590, Test Loss: 0.5213\n",
      "Epoch 14950/100000, Train Loss: 0.4590, Test Loss: 0.5213\n",
      "Epoch 15000/100000, Train Loss: 0.4589, Test Loss: 0.5213\n",
      "Epoch 15050/100000, Train Loss: 0.4589, Test Loss: 0.5213\n",
      "Epoch 15100/100000, Train Loss: 0.4588, Test Loss: 0.5212\n",
      "Epoch 15150/100000, Train Loss: 0.4587, Test Loss: 0.5212\n",
      "Epoch 15200/100000, Train Loss: 0.4587, Test Loss: 0.5212\n",
      "Epoch 15250/100000, Train Loss: 0.4586, Test Loss: 0.5212\n",
      "Epoch 15300/100000, Train Loss: 0.4586, Test Loss: 0.5212\n",
      "Epoch 15350/100000, Train Loss: 0.4585, Test Loss: 0.5212\n",
      "Epoch 15400/100000, Train Loss: 0.4585, Test Loss: 0.5211\n",
      "Epoch 15450/100000, Train Loss: 0.4584, Test Loss: 0.5211\n",
      "Epoch 15500/100000, Train Loss: 0.4584, Test Loss: 0.5211\n",
      "Epoch 15550/100000, Train Loss: 0.4583, Test Loss: 0.5211\n",
      "Epoch 15600/100000, Train Loss: 0.4583, Test Loss: 0.5211\n",
      "Epoch 15650/100000, Train Loss: 0.4582, Test Loss: 0.5211\n",
      "Epoch 15700/100000, Train Loss: 0.4582, Test Loss: 0.5211\n",
      "Epoch 15750/100000, Train Loss: 0.4581, Test Loss: 0.5210\n",
      "Epoch 15800/100000, Train Loss: 0.4581, Test Loss: 0.5210\n",
      "Epoch 15850/100000, Train Loss: 0.4580, Test Loss: 0.5210\n",
      "Epoch 15900/100000, Train Loss: 0.4580, Test Loss: 0.5210\n",
      "Epoch 15950/100000, Train Loss: 0.4579, Test Loss: 0.5210\n",
      "Epoch 16000/100000, Train Loss: 0.4579, Test Loss: 0.5210\n",
      "Epoch 16050/100000, Train Loss: 0.4578, Test Loss: 0.5210\n",
      "Epoch 16100/100000, Train Loss: 0.4578, Test Loss: 0.5210\n",
      "Epoch 16150/100000, Train Loss: 0.4577, Test Loss: 0.5209\n",
      "Epoch 16200/100000, Train Loss: 0.4577, Test Loss: 0.5209\n",
      "Epoch 16250/100000, Train Loss: 0.4576, Test Loss: 0.5209\n",
      "Epoch 16300/100000, Train Loss: 0.4576, Test Loss: 0.5209\n",
      "Epoch 16350/100000, Train Loss: 0.4575, Test Loss: 0.5209\n",
      "Epoch 16400/100000, Train Loss: 0.4575, Test Loss: 0.5209\n",
      "Epoch 16450/100000, Train Loss: 0.4574, Test Loss: 0.5209\n",
      "Epoch 16500/100000, Train Loss: 0.4574, Test Loss: 0.5209\n",
      "Epoch 16550/100000, Train Loss: 0.4573, Test Loss: 0.5209\n",
      "Epoch 16600/100000, Train Loss: 0.4573, Test Loss: 0.5208\n",
      "Epoch 16650/100000, Train Loss: 0.4573, Test Loss: 0.5208\n",
      "Epoch 16700/100000, Train Loss: 0.4572, Test Loss: 0.5208\n",
      "Epoch 16750/100000, Train Loss: 0.4572, Test Loss: 0.5208\n",
      "Epoch 16800/100000, Train Loss: 0.4571, Test Loss: 0.5208\n",
      "Epoch 16850/100000, Train Loss: 0.4571, Test Loss: 0.5208\n",
      "Epoch 16900/100000, Train Loss: 0.4571, Test Loss: 0.5208\n",
      "Epoch 16950/100000, Train Loss: 0.4570, Test Loss: 0.5208\n",
      "Epoch 17000/100000, Train Loss: 0.4570, Test Loss: 0.5208\n",
      "Epoch 17050/100000, Train Loss: 0.4569, Test Loss: 0.5208\n",
      "Epoch 17100/100000, Train Loss: 0.4569, Test Loss: 0.5208\n",
      "Epoch 17150/100000, Train Loss: 0.4569, Test Loss: 0.5207\n",
      "Epoch 17200/100000, Train Loss: 0.4568, Test Loss: 0.5207\n",
      "Epoch 17250/100000, Train Loss: 0.4568, Test Loss: 0.5207\n",
      "Epoch 17300/100000, Train Loss: 0.4567, Test Loss: 0.5207\n",
      "Epoch 17350/100000, Train Loss: 0.4567, Test Loss: 0.5207\n",
      "Epoch 17400/100000, Train Loss: 0.4567, Test Loss: 0.5207\n",
      "Epoch 17450/100000, Train Loss: 0.4566, Test Loss: 0.5207\n",
      "Epoch 17500/100000, Train Loss: 0.4566, Test Loss: 0.5207\n",
      "Epoch 17550/100000, Train Loss: 0.4566, Test Loss: 0.5207\n",
      "Epoch 17600/100000, Train Loss: 0.4565, Test Loss: 0.5207\n",
      "Epoch 17650/100000, Train Loss: 0.4565, Test Loss: 0.5207\n",
      "Epoch 17700/100000, Train Loss: 0.4564, Test Loss: 0.5207\n",
      "Epoch 17750/100000, Train Loss: 0.4564, Test Loss: 0.5207\n",
      "Epoch 17800/100000, Train Loss: 0.4564, Test Loss: 0.5207\n",
      "Epoch 17850/100000, Train Loss: 0.4563, Test Loss: 0.5206\n",
      "Epoch 17900/100000, Train Loss: 0.4563, Test Loss: 0.5206\n",
      "Epoch 17950/100000, Train Loss: 0.4563, Test Loss: 0.5206\n",
      "Epoch 18000/100000, Train Loss: 0.4562, Test Loss: 0.5206\n",
      "Epoch 18050/100000, Train Loss: 0.4562, Test Loss: 0.5206\n",
      "Epoch 18100/100000, Train Loss: 0.4562, Test Loss: 0.5206\n",
      "Epoch 18150/100000, Train Loss: 0.4561, Test Loss: 0.5206\n",
      "Epoch 18200/100000, Train Loss: 0.4561, Test Loss: 0.5206\n",
      "Epoch 18250/100000, Train Loss: 0.4561, Test Loss: 0.5206\n",
      "Epoch 18300/100000, Train Loss: 0.4561, Test Loss: 0.5206\n",
      "Epoch 18350/100000, Train Loss: 0.4560, Test Loss: 0.5206\n",
      "Epoch 18400/100000, Train Loss: 0.4560, Test Loss: 0.5206\n",
      "Epoch 18450/100000, Train Loss: 0.4560, Test Loss: 0.5206\n",
      "Epoch 18500/100000, Train Loss: 0.4559, Test Loss: 0.5206\n",
      "Epoch 18550/100000, Train Loss: 0.4559, Test Loss: 0.5206\n",
      "Epoch 18600/100000, Train Loss: 0.4559, Test Loss: 0.5206\n",
      "Epoch 18650/100000, Train Loss: 0.4558, Test Loss: 0.5206\n",
      "Epoch 18700/100000, Train Loss: 0.4558, Test Loss: 0.5206\n",
      "Epoch 18750/100000, Train Loss: 0.4558, Test Loss: 0.5206\n",
      "Epoch 18800/100000, Train Loss: 0.4557, Test Loss: 0.5206\n",
      "Epoch 18850/100000, Train Loss: 0.4557, Test Loss: 0.5205\n",
      "Epoch 18900/100000, Train Loss: 0.4557, Test Loss: 0.5205\n",
      "Epoch 18950/100000, Train Loss: 0.4557, Test Loss: 0.5205\n",
      "Epoch 19000/100000, Train Loss: 0.4556, Test Loss: 0.5205\n",
      "Epoch 19050/100000, Train Loss: 0.4556, Test Loss: 0.5205\n",
      "Epoch 19100/100000, Train Loss: 0.4556, Test Loss: 0.5205\n",
      "Epoch 19150/100000, Train Loss: 0.4556, Test Loss: 0.5205\n",
      "Epoch 19200/100000, Train Loss: 0.4555, Test Loss: 0.5205\n",
      "Epoch 19250/100000, Train Loss: 0.4555, Test Loss: 0.5205\n",
      "Epoch 19300/100000, Train Loss: 0.4555, Test Loss: 0.5205\n",
      "Epoch 19350/100000, Train Loss: 0.4554, Test Loss: 0.5205\n",
      "Epoch 19400/100000, Train Loss: 0.4554, Test Loss: 0.5205\n",
      "Epoch 19450/100000, Train Loss: 0.4554, Test Loss: 0.5205\n",
      "Epoch 19500/100000, Train Loss: 0.4554, Test Loss: 0.5205\n",
      "Epoch 19550/100000, Train Loss: 0.4553, Test Loss: 0.5205\n",
      "Epoch 19600/100000, Train Loss: 0.4553, Test Loss: 0.5205\n",
      "Epoch 19650/100000, Train Loss: 0.4553, Test Loss: 0.5205\n",
      "Epoch 19700/100000, Train Loss: 0.4553, Test Loss: 0.5205\n",
      "Epoch 19750/100000, Train Loss: 0.4552, Test Loss: 0.5205\n",
      "Epoch 19800/100000, Train Loss: 0.4552, Test Loss: 0.5205\n",
      "Epoch 19850/100000, Train Loss: 0.4552, Test Loss: 0.5205\n",
      "Epoch 19900/100000, Train Loss: 0.4552, Test Loss: 0.5205\n",
      "Epoch 19950/100000, Train Loss: 0.4552, Test Loss: 0.5205\n",
      "Epoch 20000/100000, Train Loss: 0.4551, Test Loss: 0.5205\n",
      "Epoch 20050/100000, Train Loss: 0.4551, Test Loss: 0.5205\n",
      "Epoch 20100/100000, Train Loss: 0.4551, Test Loss: 0.5205\n",
      "Epoch 20150/100000, Train Loss: 0.4551, Test Loss: 0.5205\n",
      "Epoch 20200/100000, Train Loss: 0.4550, Test Loss: 0.5205\n",
      "Epoch 20250/100000, Train Loss: 0.4550, Test Loss: 0.5205\n",
      "Epoch 20300/100000, Train Loss: 0.4550, Test Loss: 0.5205\n",
      "Epoch 20350/100000, Train Loss: 0.4550, Test Loss: 0.5205\n",
      "Epoch 20400/100000, Train Loss: 0.4549, Test Loss: 0.5205\n",
      "Epoch 20450/100000, Train Loss: 0.4549, Test Loss: 0.5205\n",
      "Epoch 20500/100000, Train Loss: 0.4549, Test Loss: 0.5205\n",
      "Epoch 20550/100000, Train Loss: 0.4549, Test Loss: 0.5205\n",
      "Epoch 20600/100000, Train Loss: 0.4549, Test Loss: 0.5205\n",
      "Epoch 20650/100000, Train Loss: 0.4548, Test Loss: 0.5205\n",
      "Epoch 20700/100000, Train Loss: 0.4548, Test Loss: 0.5205\n",
      "Epoch 20750/100000, Train Loss: 0.4548, Test Loss: 0.5205\n",
      "Epoch 20800/100000, Train Loss: 0.4548, Test Loss: 0.5205\n",
      "Epoch 20850/100000, Train Loss: 0.4548, Test Loss: 0.5205\n",
      "Epoch 20900/100000, Train Loss: 0.4547, Test Loss: 0.5205\n",
      "Epoch 20950/100000, Train Loss: 0.4547, Test Loss: 0.5205\n",
      "Epoch 21000/100000, Train Loss: 0.4547, Test Loss: 0.5205\n",
      "Epoch 21050/100000, Train Loss: 0.4547, Test Loss: 0.5205\n",
      "Epoch 21100/100000, Train Loss: 0.4547, Test Loss: 0.5205\n",
      "Epoch 21150/100000, Train Loss: 0.4546, Test Loss: 0.5205\n",
      "Epoch 21200/100000, Train Loss: 0.4546, Test Loss: 0.5205\n",
      "Epoch 21250/100000, Train Loss: 0.4546, Test Loss: 0.5205\n",
      "Epoch 21300/100000, Train Loss: 0.4546, Test Loss: 0.5205\n",
      "Epoch 21350/100000, Train Loss: 0.4546, Test Loss: 0.5205\n",
      "Epoch 21400/100000, Train Loss: 0.4546, Test Loss: 0.5205\n",
      "Epoch 21450/100000, Train Loss: 0.4545, Test Loss: 0.5205\n",
      "Epoch 21500/100000, Train Loss: 0.4545, Test Loss: 0.5205\n",
      "Epoch 21550/100000, Train Loss: 0.4545, Test Loss: 0.5205\n",
      "Epoch 21600/100000, Train Loss: 0.4545, Test Loss: 0.5205\n",
      "Epoch 21650/100000, Train Loss: 0.4545, Test Loss: 0.5205\n",
      "Epoch 21700/100000, Train Loss: 0.4544, Test Loss: 0.5205\n",
      "Epoch 21750/100000, Train Loss: 0.4544, Test Loss: 0.5205\n",
      "Epoch 21800/100000, Train Loss: 0.4544, Test Loss: 0.5205\n",
      "Epoch 21850/100000, Train Loss: 0.4544, Test Loss: 0.5205\n",
      "Epoch 21900/100000, Train Loss: 0.4544, Test Loss: 0.5205\n",
      "Epoch 21950/100000, Train Loss: 0.4544, Test Loss: 0.5205\n",
      "Epoch 22000/100000, Train Loss: 0.4543, Test Loss: 0.5205\n",
      "Epoch 22050/100000, Train Loss: 0.4543, Test Loss: 0.5205\n",
      "Epoch 22100/100000, Train Loss: 0.4543, Test Loss: 0.5205\n",
      "Epoch 22150/100000, Train Loss: 0.4543, Test Loss: 0.5205\n",
      "Epoch 22200/100000, Train Loss: 0.4543, Test Loss: 0.5205\n",
      "Epoch 22250/100000, Train Loss: 0.4543, Test Loss: 0.5205\n",
      "Epoch 22300/100000, Train Loss: 0.4542, Test Loss: 0.5205\n",
      "Epoch 22350/100000, Train Loss: 0.4542, Test Loss: 0.5205\n",
      "Epoch 22400/100000, Train Loss: 0.4542, Test Loss: 0.5205\n",
      "Epoch 22450/100000, Train Loss: 0.4542, Test Loss: 0.5205\n",
      "Epoch 22500/100000, Train Loss: 0.4542, Test Loss: 0.5205\n",
      "Epoch 22550/100000, Train Loss: 0.4542, Test Loss: 0.5205\n",
      "Epoch 22600/100000, Train Loss: 0.4542, Test Loss: 0.5205\n",
      "Epoch 22650/100000, Train Loss: 0.4541, Test Loss: 0.5205\n",
      "Epoch 22700/100000, Train Loss: 0.4541, Test Loss: 0.5205\n",
      "Epoch 22750/100000, Train Loss: 0.4541, Test Loss: 0.5205\n",
      "Epoch 22800/100000, Train Loss: 0.4541, Test Loss: 0.5205\n",
      "Epoch 22850/100000, Train Loss: 0.4541, Test Loss: 0.5205\n",
      "Epoch 22900/100000, Train Loss: 0.4541, Test Loss: 0.5205\n",
      "Epoch 22950/100000, Train Loss: 0.4541, Test Loss: 0.5205\n",
      "Epoch 23000/100000, Train Loss: 0.4540, Test Loss: 0.5205\n",
      "Epoch 23050/100000, Train Loss: 0.4540, Test Loss: 0.5205\n",
      "Epoch 23100/100000, Train Loss: 0.4540, Test Loss: 0.5205\n",
      "Epoch 23150/100000, Train Loss: 0.4540, Test Loss: 0.5205\n",
      "Epoch 23200/100000, Train Loss: 0.4540, Test Loss: 0.5205\n",
      "Epoch 23250/100000, Train Loss: 0.4540, Test Loss: 0.5205\n",
      "Epoch 23300/100000, Train Loss: 0.4540, Test Loss: 0.5205\n",
      "Epoch 23350/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23400/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23450/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23500/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23550/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23600/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23650/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23700/100000, Train Loss: 0.4539, Test Loss: 0.5205\n",
      "Epoch 23750/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 23800/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 23850/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 23900/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 23950/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 24000/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 24050/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 24100/100000, Train Loss: 0.4538, Test Loss: 0.5205\n",
      "Epoch 24150/100000, Train Loss: 0.4537, Test Loss: 0.5205\n",
      "Epoch 24200/100000, Train Loss: 0.4537, Test Loss: 0.5205\n",
      "Epoch 24250/100000, Train Loss: 0.4537, Test Loss: 0.5205\n",
      "Epoch 24300/100000, Train Loss: 0.4537, Test Loss: 0.5205\n",
      "Epoch 24350/100000, Train Loss: 0.4537, Test Loss: 0.5205\n",
      "Epoch 24400/100000, Train Loss: 0.4537, Test Loss: 0.5206\n",
      "Epoch 24450/100000, Train Loss: 0.4537, Test Loss: 0.5206\n",
      "Epoch 24500/100000, Train Loss: 0.4537, Test Loss: 0.5206\n",
      "Epoch 24550/100000, Train Loss: 0.4537, Test Loss: 0.5206\n",
      "Epoch 24600/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 24650/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 24700/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 24750/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 24800/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 24850/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 24900/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 24950/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 25000/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 25050/100000, Train Loss: 0.4536, Test Loss: 0.5206\n",
      "Epoch 25100/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25150/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25200/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25250/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25300/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25350/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25400/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25450/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25500/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25550/100000, Train Loss: 0.4535, Test Loss: 0.5206\n",
      "Epoch 25600/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 25650/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 25700/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 25750/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 25800/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 25850/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 25900/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 25950/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 26000/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 26050/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 26100/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 26150/100000, Train Loss: 0.4534, Test Loss: 0.5206\n",
      "Epoch 26200/100000, Train Loss: 0.4533, Test Loss: 0.5206\n",
      "Epoch 26250/100000, Train Loss: 0.4533, Test Loss: 0.5206\n",
      "Epoch 26300/100000, Train Loss: 0.4533, Test Loss: 0.5206\n",
      "Epoch 26350/100000, Train Loss: 0.4533, Test Loss: 0.5206\n",
      "Epoch 26400/100000, Train Loss: 0.4533, Test Loss: 0.5206\n",
      "Epoch 26450/100000, Train Loss: 0.4533, Test Loss: 0.5207\n",
      "Epoch 26500/100000, Train Loss: 0.4533, Test Loss: 0.5207\n",
      "Epoch 26550/100000, Train Loss: 0.4533, Test Loss: 0.5207\n",
      "Epoch 26600/100000, Train Loss: 0.4533, Test Loss: 0.5207\n",
      "Epoch 26650/100000, Train Loss: 0.4533, Test Loss: 0.5207\n",
      "Epoch 26700/100000, Train Loss: 0.4533, Test Loss: 0.5207\n",
      "Epoch 26750/100000, Train Loss: 0.4533, Test Loss: 0.5207\n",
      "Epoch 26800/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 26850/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 26900/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 26950/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27000/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27050/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27100/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27150/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27200/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27250/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27300/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27350/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27400/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27450/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27500/100000, Train Loss: 0.4532, Test Loss: 0.5207\n",
      "Epoch 27550/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27600/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27650/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27700/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27750/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27800/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27850/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27900/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 27950/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 28000/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 28050/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 28100/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 28150/100000, Train Loss: 0.4531, Test Loss: 0.5207\n",
      "Epoch 28200/100000, Train Loss: 0.4531, Test Loss: 0.5208\n",
      "Epoch 28250/100000, Train Loss: 0.4531, Test Loss: 0.5208\n",
      "Epoch 28300/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28350/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28400/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28450/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28500/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28550/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28600/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28650/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28700/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28750/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28800/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28850/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28900/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 28950/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 29000/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 29050/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 29100/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 29150/100000, Train Loss: 0.4530, Test Loss: 0.5208\n",
      "Epoch 29200/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29250/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29300/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29350/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29400/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29450/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29500/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29550/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29600/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29650/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29700/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29750/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29800/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29850/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29900/100000, Train Loss: 0.4529, Test Loss: 0.5208\n",
      "Epoch 29950/100000, Train Loss: 0.4529, Test Loss: 0.5209\n",
      "Epoch 30000/100000, Train Loss: 0.4529, Test Loss: 0.5209\n",
      "Epoch 30050/100000, Train Loss: 0.4529, Test Loss: 0.5209\n",
      "Epoch 30100/100000, Train Loss: 0.4529, Test Loss: 0.5209\n",
      "Epoch 30150/100000, Train Loss: 0.4529, Test Loss: 0.5209\n",
      "Epoch 30200/100000, Train Loss: 0.4529, Test Loss: 0.5209\n",
      "Epoch 30250/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30300/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30350/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30400/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30450/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30500/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30550/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30600/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30650/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30700/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30750/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30800/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30850/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30900/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 30950/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31000/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31050/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31100/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31150/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31200/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31250/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31300/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31350/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31400/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31450/100000, Train Loss: 0.4528, Test Loss: 0.5209\n",
      "Epoch 31500/100000, Train Loss: 0.4527, Test Loss: 0.5209\n",
      "Epoch 31550/100000, Train Loss: 0.4527, Test Loss: 0.5209\n",
      "Epoch 31600/100000, Train Loss: 0.4527, Test Loss: 0.5209\n",
      "Epoch 31650/100000, Train Loss: 0.4527, Test Loss: 0.5209\n",
      "Epoch 31700/100000, Train Loss: 0.4527, Test Loss: 0.5209\n",
      "Epoch 31750/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 31800/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 31850/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 31900/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 31950/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32000/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32050/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32100/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32150/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32200/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32250/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32300/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32350/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32400/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32450/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32500/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32550/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32600/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32650/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32700/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32750/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32800/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32850/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32900/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 32950/100000, Train Loss: 0.4527, Test Loss: 0.5210\n",
      "Epoch 33000/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33050/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33100/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33150/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33200/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33250/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33300/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33350/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33400/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33450/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33500/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33550/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33600/100000, Train Loss: 0.4526, Test Loss: 0.5210\n",
      "Epoch 33650/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 33700/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 33750/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 33800/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 33850/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 33900/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 33950/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34000/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34050/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34100/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34150/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34200/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34250/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34300/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34350/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34400/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34450/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34500/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34550/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34600/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34650/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34700/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34750/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34800/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34850/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34900/100000, Train Loss: 0.4526, Test Loss: 0.5211\n",
      "Epoch 34950/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35000/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35050/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35100/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35150/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35200/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35250/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35300/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35350/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35400/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35450/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35500/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35550/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35600/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35650/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35700/100000, Train Loss: 0.4525, Test Loss: 0.5211\n",
      "Epoch 35750/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 35800/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 35850/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 35900/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 35950/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36000/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36050/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36100/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36150/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36200/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36250/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36300/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36350/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36400/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36450/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36500/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36550/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36600/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36650/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36700/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36750/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36800/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36850/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36900/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 36950/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37000/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37050/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37100/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37150/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37200/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37250/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37300/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37350/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37400/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37450/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37500/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37550/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37600/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37650/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37700/100000, Train Loss: 0.4525, Test Loss: 0.5212\n",
      "Epoch 37750/100000, Train Loss: 0.4524, Test Loss: 0.5212\n",
      "Epoch 37800/100000, Train Loss: 0.4524, Test Loss: 0.5212\n",
      "Epoch 37850/100000, Train Loss: 0.4524, Test Loss: 0.5212\n",
      "Epoch 37900/100000, Train Loss: 0.4524, Test Loss: 0.5212\n",
      "Epoch 37950/100000, Train Loss: 0.4524, Test Loss: 0.5212\n",
      "Epoch 38000/100000, Train Loss: 0.4524, Test Loss: 0.5212\n",
      "Epoch 38050/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38100/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38150/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38200/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38250/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38300/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38350/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38400/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38450/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38500/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38550/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38600/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38650/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38700/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38750/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38800/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38850/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38900/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 38950/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39000/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39050/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39100/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39150/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39200/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39250/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39300/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39350/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39400/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39450/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39500/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39550/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39600/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39650/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39700/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39750/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39800/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39850/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39900/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 39950/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40000/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40050/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40100/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40150/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40200/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40250/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40300/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40350/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40400/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40450/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40500/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40550/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40600/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40650/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40700/100000, Train Loss: 0.4524, Test Loss: 0.5213\n",
      "Epoch 40750/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 40800/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 40850/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 40900/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 40950/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41000/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41050/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41100/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41150/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41200/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41250/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41300/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41350/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41400/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41450/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41500/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41550/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41600/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41650/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41700/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41750/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41800/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41850/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41900/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 41950/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42000/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42050/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42100/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42150/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42200/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42250/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42300/100000, Train Loss: 0.4524, Test Loss: 0.5214\n",
      "Epoch 42350/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42400/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42450/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42500/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42550/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42600/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42650/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42700/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42750/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42800/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42850/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42900/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 42950/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43000/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43050/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43100/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43150/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43200/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43250/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43300/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43350/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43400/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43450/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43500/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43550/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43600/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43650/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43700/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43750/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43800/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43850/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43900/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 43950/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 44000/100000, Train Loss: 0.4523, Test Loss: 0.5214\n",
      "Epoch 44050/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44100/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44150/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44200/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44250/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44300/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44350/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44400/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44450/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44500/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44550/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44600/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44650/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44700/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44750/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44800/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44850/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44900/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 44950/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45000/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45050/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45100/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45150/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45200/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45250/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45300/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45350/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45400/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45450/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45500/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45550/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45600/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45650/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45700/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45750/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45800/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45850/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45900/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 45950/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46000/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46050/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46100/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46150/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46200/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46250/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46300/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46350/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46400/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46450/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46500/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46550/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46600/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46650/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46700/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46750/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46800/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46850/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46900/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 46950/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47000/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47050/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47100/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47150/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47200/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47250/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47300/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47350/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47400/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47450/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47500/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47550/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47600/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47650/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47700/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47750/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47800/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47850/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47900/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 47950/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 48000/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 48050/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 48100/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 48150/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 48200/100000, Train Loss: 0.4523, Test Loss: 0.5215\n",
      "Epoch 48250/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48300/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48350/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48400/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48450/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48500/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48550/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48600/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48650/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48700/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48750/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48800/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48850/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48900/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 48950/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49000/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49050/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49100/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49150/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49200/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49250/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49300/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49350/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49400/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49450/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49500/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49550/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49600/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49650/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49700/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49750/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49800/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49850/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49900/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 49950/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50000/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50050/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50100/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50150/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50200/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50250/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50300/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50350/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50400/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50450/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50500/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50550/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50600/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50650/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50700/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50750/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50800/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50850/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50900/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 50950/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51000/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51050/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51100/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51150/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51200/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51250/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51300/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51350/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51400/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51450/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51500/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51550/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51600/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51650/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51700/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51750/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51800/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51850/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51900/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 51950/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52000/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52050/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52100/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52150/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52200/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52250/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52300/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52350/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52400/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52450/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52500/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52550/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52600/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52650/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52700/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52750/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52800/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52850/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52900/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 52950/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53000/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53050/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53100/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53150/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53200/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53250/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53300/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53350/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53400/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53450/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53500/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53550/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53600/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53650/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53700/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53750/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53800/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53850/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53900/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 53950/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54000/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54050/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54100/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54150/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54200/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54250/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54300/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54350/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54400/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54450/100000, Train Loss: 0.4523, Test Loss: 0.5216\n",
      "Epoch 54500/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54550/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54600/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54650/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54700/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54750/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54800/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54850/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54900/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 54950/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55000/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55050/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55100/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55150/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55200/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55250/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55300/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55350/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55400/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55450/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55500/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55550/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55600/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55650/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55700/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55750/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55800/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55850/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55900/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 55950/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56000/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56050/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56100/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56150/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56200/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56250/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56300/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56350/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56400/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56450/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56500/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56550/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56600/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56650/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56700/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56750/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56800/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56850/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56900/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 56950/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57000/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57050/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57100/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57150/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57200/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57250/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57300/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57350/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57400/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57450/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57500/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57550/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57600/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57650/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57700/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57750/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57800/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57850/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57900/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 57950/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58000/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58050/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58100/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58150/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58200/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58250/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58300/100000, Train Loss: 0.4523, Test Loss: 0.5217\n",
      "Epoch 58350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 58950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 59950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 60950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 61950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 62950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 63950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 64950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 65950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 66950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67200/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67250/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67300/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67350/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67400/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67450/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67500/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67550/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67600/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67650/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67700/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67750/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67800/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67850/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67900/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 67950/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 68000/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 68050/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 68100/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 68150/100000, Train Loss: 0.4522, Test Loss: 0.5217\n",
      "Epoch 68200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 68950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 69950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 70950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 71950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 72950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 73950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 74950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 75950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 76950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 77950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 78950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 79950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 80950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 81950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 82950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 83950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 84950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 85950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 86950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 87950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 88950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 89950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 90950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 91950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 92950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 93950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 94950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 95950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 96950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 97950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 98950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99050/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99100/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99150/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99200/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99250/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99300/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99350/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99400/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99450/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99500/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99550/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99600/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99650/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99700/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99750/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99800/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99850/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99900/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 99950/100000, Train Loss: 0.4522, Test Loss: 0.5218\n",
      "Epoch 100000/100000, Train Loss: 0.4522, Test Loss: 0.5218\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "n_epochs = 100000\n",
    "train_losses = np.zeros(n_epochs) \n",
    "test_losses = np.zeros(n_epochs)\n",
    "\n",
    "for it in range(n_epochs):\n",
    "  optimizer.zero_grad()\n",
    "  #training loss\n",
    "  outputs = model(input_tensor)\n",
    "  loss = criterion(outputs, targets)\n",
    "  #optimize\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  #test loss\n",
    "  outputs_tst = model(input_tst_tensor)\n",
    "  loss_tst = criterion(outputs_tst, targets_tst)\n",
    "  #save the losses\n",
    "  train_losses[it] = loss.item()\n",
    "  test_losses[it] = loss_tst.item()\n",
    "  \n",
    "  if (it+1) % 50 == 0:\n",
    "    print(f'Epoch {it+1}/{n_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {loss_tst.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tendency of the losses\n",
    "plt.plot(train_losses, label='train_losses')\n",
    "plt.plot(test_losses, label='test_losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8008, Test acc: 0.7165\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "\n",
    "with torch.no_grad():\n",
    "  p_train = model(input_tensor)\n",
    "  p_train = np.round(p_train.numpy())\n",
    "  train_acc = np.mean(targets.numpy() == p_train)\n",
    "\n",
    "  p_test = model(input_tst_tensor)\n",
    "  p_test = np.round(p_test.numpy())\n",
    "  test_acc = np.mean(targets_tst.numpy() == p_test)\n",
    "print(f'Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
