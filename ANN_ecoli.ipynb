{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SequenceName   mcg   gvh   lip  chg   aac  alm1  alm2 ClassDistribution\n",
      "0      AAT_ECOLI  0.49  0.29  0.48  0.5  0.56  0.24  0.35                cp\n",
      "1     ACEA_ECOLI  0.07  0.40  0.48  0.5  0.54  0.35  0.44                cp\n",
      "2     ACEK_ECOLI  0.56  0.40  0.48  0.5  0.49  0.37  0.46                cp\n",
      "3     ACKA_ECOLI  0.59  0.49  0.48  0.5  0.52  0.45  0.36                cp\n",
      "4      ADI_ECOLI  0.23  0.32  0.48  0.5  0.55  0.25  0.35                cp\n",
      "..           ...   ...   ...   ...  ...   ...   ...   ...               ...\n",
      "331   TREA_ECOLI  0.74  0.56  0.48  0.5  0.47  0.68  0.30                pp\n",
      "332   UGPB_ECOLI  0.71  0.57  0.48  0.5  0.48  0.35  0.32                pp\n",
      "333   USHA_ECOLI  0.61  0.60  0.48  0.5  0.44  0.39  0.38                pp\n",
      "334   XYLF_ECOLI  0.59  0.61  0.48  0.5  0.42  0.42  0.37                pp\n",
      "335   YTFQ_ECOLI  0.74  0.74  0.48  0.5  0.31  0.53  0.52                pp\n",
      "\n",
      "[336 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "hd = ('SequenceName','mcg','gvh','lip','chg','aac','alm1','alm2','ClassDistribution')\n",
    "\n",
    "df = pd.read_csv(\"ecoli.data\", sep='\\s+', names= hd)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49 0.29 0.48 ... 0.24 0.35 'cp']\n",
      " [0.07 0.4 0.48 ... 0.35 0.44 'cp']\n",
      " [0.56 0.4 0.48 ... 0.37 0.46 'cp']\n",
      " ...\n",
      " [0.61 0.6 0.48 ... 0.39 0.38 'pp']\n",
      " [0.59 0.61 0.48 ... 0.42 0.37 'pp']\n",
      " [0.74 0.74 0.48 ... 0.53 0.52 'pp']]\n",
      "[[0.68 0.76 0.48 ... 0.45 0.27 'om']\n",
      " [0.33 0.45 0.48 ... 0.88 0.89 'im']\n",
      " [0.36 0.56 0.48 ... 0.45 0.53 'cp']\n",
      " ...\n",
      " [0.75 0.37 0.48 ... 0.7 0.74 'imU']\n",
      " [0.21 0.51 0.48 ... 0.32 0.41 'cp']\n",
      " [0.35 0.34 0.48 ... 0.3 0.27 'cp']]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "col = [['cp',\n",
    "  'im',\n",
    "  'pp',\n",
    "  'imU',\n",
    "  'om',\n",
    "  'omL',\n",
    "  'imL',\n",
    "  'imS']]\n",
    "\n",
    "df2 = df.iloc[:,1:]\n",
    "data = df2.to_numpy()\n",
    "print(data)\n",
    "rd.shuffle(data)\n",
    "print(data)\n",
    "col = np.asarray(col).reshape(1,8)\n",
    "vals = data[:,-1:].reshape(336,1)\n",
    "matrix = np.zeros((336,8))\n",
    "for i in range(vals.shape[0]):\n",
    "  for j in range(col.shape[1]):\n",
    "    if(col[0,j] == vals[i,0]):\n",
    "      matrix[i,j] = 1\n",
    "      break\n",
    "\n",
    "\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_297181/2742568034.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  Xtn = (Xt-Xt_m)/Xt_s\n"
     ]
    }
   ],
   "source": [
    "X = data[:round(data.shape[0]*0.666),:-1].astype(np.float32)\n",
    "Y = matrix[:round(data.shape[0]*0.666),:].astype(np.float32)\n",
    "Xt = data[round(data.shape[0]*0.666)+1:,:-1].astype(np.float32)\n",
    "Yt = matrix[round(data.shape[0]*0.666)+1:,:].astype(np.float32)\n",
    "X_m = np.mean(X,axis=0)\n",
    "Xt_m = np.mean(Xt,axis=0)\n",
    "X_s = np.std(X,axis =0)\n",
    "Xt_s = np.std(Xt,axis =0)\n",
    "\n",
    "\n",
    "Xn = (X-X_m)/X_s\n",
    "Xtn = (Xt-Xt_m)/Xt_s\n",
    "\n",
    "#variation in column 4, is 0. So I remove it\n",
    "Xn = np.delete(Xn,3,1)\n",
    "Xtn = np.delete(Xtn,3,1)\n",
    "\n",
    "inputs = torch.from_numpy(Xn)\n",
    "inputs_test = torch.from_numpy(Xtn)\n",
    "\n",
    "targets = torch.from_numpy(Y)\n",
    "targets_test = torch.from_numpy(Yt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "  nn.Linear(6,15),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(15,8)\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Train Losses: 2.1681, Test Losses: 2.1413\n",
      "Epoch 2/1000, Train Losses: 2.1610, Test Losses: 2.1340\n",
      "Epoch 3/1000, Train Losses: 2.1541, Test Losses: 2.1266\n",
      "Epoch 4/1000, Train Losses: 2.1471, Test Losses: 2.1194\n",
      "Epoch 5/1000, Train Losses: 2.1403, Test Losses: 2.1122\n",
      "Epoch 6/1000, Train Losses: 2.1334, Test Losses: 2.1050\n",
      "Epoch 7/1000, Train Losses: 2.1266, Test Losses: 2.0979\n",
      "Epoch 8/1000, Train Losses: 2.1199, Test Losses: 2.0908\n",
      "Epoch 9/1000, Train Losses: 2.1132, Test Losses: 2.0838\n",
      "Epoch 10/1000, Train Losses: 2.1066, Test Losses: 2.0768\n",
      "Epoch 11/1000, Train Losses: 2.1000, Test Losses: 2.0699\n",
      "Epoch 12/1000, Train Losses: 2.0934, Test Losses: 2.0630\n",
      "Epoch 13/1000, Train Losses: 2.0869, Test Losses: 2.0562\n",
      "Epoch 14/1000, Train Losses: 2.0804, Test Losses: 2.0494\n",
      "Epoch 15/1000, Train Losses: 2.0739, Test Losses: 2.0427\n",
      "Epoch 16/1000, Train Losses: 2.0675, Test Losses: 2.0361\n",
      "Epoch 17/1000, Train Losses: 2.0612, Test Losses: 2.0294\n",
      "Epoch 18/1000, Train Losses: 2.0548, Test Losses: 2.0228\n",
      "Epoch 19/1000, Train Losses: 2.0486, Test Losses: 2.0163\n",
      "Epoch 20/1000, Train Losses: 2.0423, Test Losses: 2.0097\n",
      "Epoch 21/1000, Train Losses: 2.0361, Test Losses: 2.0032\n",
      "Epoch 22/1000, Train Losses: 2.0299, Test Losses: 1.9968\n",
      "Epoch 23/1000, Train Losses: 2.0238, Test Losses: 1.9903\n",
      "Epoch 24/1000, Train Losses: 2.0176, Test Losses: 1.9839\n",
      "Epoch 25/1000, Train Losses: 2.0115, Test Losses: 1.9775\n",
      "Epoch 26/1000, Train Losses: 2.0055, Test Losses: 1.9711\n",
      "Epoch 27/1000, Train Losses: 1.9994, Test Losses: 1.9648\n",
      "Epoch 28/1000, Train Losses: 1.9934, Test Losses: 1.9585\n",
      "Epoch 29/1000, Train Losses: 1.9873, Test Losses: 1.9521\n",
      "Epoch 30/1000, Train Losses: 1.9814, Test Losses: 1.9459\n",
      "Epoch 31/1000, Train Losses: 1.9754, Test Losses: 1.9396\n",
      "Epoch 32/1000, Train Losses: 1.9694, Test Losses: 1.9333\n",
      "Epoch 33/1000, Train Losses: 1.9635, Test Losses: 1.9271\n",
      "Epoch 34/1000, Train Losses: 1.9575, Test Losses: 1.9209\n",
      "Epoch 35/1000, Train Losses: 1.9516, Test Losses: 1.9146\n",
      "Epoch 36/1000, Train Losses: 1.9457, Test Losses: 1.9084\n",
      "Epoch 37/1000, Train Losses: 1.9397, Test Losses: 1.9022\n",
      "Epoch 38/1000, Train Losses: 1.9338, Test Losses: 1.8960\n",
      "Epoch 39/1000, Train Losses: 1.9279, Test Losses: 1.8898\n",
      "Epoch 40/1000, Train Losses: 1.9219, Test Losses: 1.8835\n",
      "Epoch 41/1000, Train Losses: 1.9160, Test Losses: 1.8773\n",
      "Epoch 42/1000, Train Losses: 1.9101, Test Losses: 1.8711\n",
      "Epoch 43/1000, Train Losses: 1.9041, Test Losses: 1.8649\n",
      "Epoch 44/1000, Train Losses: 1.8981, Test Losses: 1.8586\n",
      "Epoch 45/1000, Train Losses: 1.8921, Test Losses: 1.8524\n",
      "Epoch 46/1000, Train Losses: 1.8861, Test Losses: 1.8461\n",
      "Epoch 47/1000, Train Losses: 1.8801, Test Losses: 1.8398\n",
      "Epoch 48/1000, Train Losses: 1.8740, Test Losses: 1.8335\n",
      "Epoch 49/1000, Train Losses: 1.8679, Test Losses: 1.8272\n",
      "Epoch 50/1000, Train Losses: 1.8618, Test Losses: 1.8208\n",
      "Epoch 51/1000, Train Losses: 1.8557, Test Losses: 1.8144\n",
      "Epoch 52/1000, Train Losses: 1.8495, Test Losses: 1.8080\n",
      "Epoch 53/1000, Train Losses: 1.8433, Test Losses: 1.8015\n",
      "Epoch 54/1000, Train Losses: 1.8371, Test Losses: 1.7950\n",
      "Epoch 55/1000, Train Losses: 1.8308, Test Losses: 1.7885\n",
      "Epoch 56/1000, Train Losses: 1.8246, Test Losses: 1.7820\n",
      "Epoch 57/1000, Train Losses: 1.8182, Test Losses: 1.7754\n",
      "Epoch 58/1000, Train Losses: 1.8119, Test Losses: 1.7688\n",
      "Epoch 59/1000, Train Losses: 1.8055, Test Losses: 1.7621\n",
      "Epoch 60/1000, Train Losses: 1.7990, Test Losses: 1.7555\n",
      "Epoch 61/1000, Train Losses: 1.7926, Test Losses: 1.7487\n",
      "Epoch 62/1000, Train Losses: 1.7860, Test Losses: 1.7419\n",
      "Epoch 63/1000, Train Losses: 1.7795, Test Losses: 1.7351\n",
      "Epoch 64/1000, Train Losses: 1.7729, Test Losses: 1.7283\n",
      "Epoch 65/1000, Train Losses: 1.7662, Test Losses: 1.7214\n",
      "Epoch 66/1000, Train Losses: 1.7595, Test Losses: 1.7144\n",
      "Epoch 67/1000, Train Losses: 1.7528, Test Losses: 1.7074\n",
      "Epoch 68/1000, Train Losses: 1.7460, Test Losses: 1.7004\n",
      "Epoch 69/1000, Train Losses: 1.7391, Test Losses: 1.6933\n",
      "Epoch 70/1000, Train Losses: 1.7322, Test Losses: 1.6861\n",
      "Epoch 71/1000, Train Losses: 1.7253, Test Losses: 1.6789\n",
      "Epoch 72/1000, Train Losses: 1.7182, Test Losses: 1.6716\n",
      "Epoch 73/1000, Train Losses: 1.7112, Test Losses: 1.6643\n",
      "Epoch 74/1000, Train Losses: 1.7041, Test Losses: 1.6569\n",
      "Epoch 75/1000, Train Losses: 1.6969, Test Losses: 1.6495\n",
      "Epoch 76/1000, Train Losses: 1.6897, Test Losses: 1.6421\n",
      "Epoch 77/1000, Train Losses: 1.6825, Test Losses: 1.6346\n",
      "Epoch 78/1000, Train Losses: 1.6752, Test Losses: 1.6270\n",
      "Epoch 79/1000, Train Losses: 1.6679, Test Losses: 1.6194\n",
      "Epoch 80/1000, Train Losses: 1.6605, Test Losses: 1.6118\n",
      "Epoch 81/1000, Train Losses: 1.6531, Test Losses: 1.6041\n",
      "Epoch 82/1000, Train Losses: 1.6457, Test Losses: 1.5963\n",
      "Epoch 83/1000, Train Losses: 1.6382, Test Losses: 1.5886\n",
      "Epoch 84/1000, Train Losses: 1.6306, Test Losses: 1.5808\n",
      "Epoch 85/1000, Train Losses: 1.6231, Test Losses: 1.5729\n",
      "Epoch 86/1000, Train Losses: 1.6155, Test Losses: 1.5650\n",
      "Epoch 87/1000, Train Losses: 1.6078, Test Losses: 1.5571\n",
      "Epoch 88/1000, Train Losses: 1.6001, Test Losses: 1.5492\n",
      "Epoch 89/1000, Train Losses: 1.5924, Test Losses: 1.5412\n",
      "Epoch 90/1000, Train Losses: 1.5846, Test Losses: 1.5331\n",
      "Epoch 91/1000, Train Losses: 1.5767, Test Losses: 1.5250\n",
      "Epoch 92/1000, Train Losses: 1.5689, Test Losses: 1.5169\n",
      "Epoch 93/1000, Train Losses: 1.5610, Test Losses: 1.5087\n",
      "Epoch 94/1000, Train Losses: 1.5530, Test Losses: 1.5005\n",
      "Epoch 95/1000, Train Losses: 1.5450, Test Losses: 1.4923\n",
      "Epoch 96/1000, Train Losses: 1.5370, Test Losses: 1.4840\n",
      "Epoch 97/1000, Train Losses: 1.5289, Test Losses: 1.4757\n",
      "Epoch 98/1000, Train Losses: 1.5209, Test Losses: 1.4673\n",
      "Epoch 99/1000, Train Losses: 1.5127, Test Losses: 1.4589\n",
      "Epoch 100/1000, Train Losses: 1.5045, Test Losses: 1.4505\n",
      "Epoch 101/1000, Train Losses: 1.4963, Test Losses: 1.4420\n",
      "Epoch 102/1000, Train Losses: 1.4881, Test Losses: 1.4335\n",
      "Epoch 103/1000, Train Losses: 1.4798, Test Losses: 1.4250\n",
      "Epoch 104/1000, Train Losses: 1.4715, Test Losses: 1.4164\n",
      "Epoch 105/1000, Train Losses: 1.4632, Test Losses: 1.4078\n",
      "Epoch 106/1000, Train Losses: 1.4548, Test Losses: 1.3992\n",
      "Epoch 107/1000, Train Losses: 1.4464, Test Losses: 1.3906\n",
      "Epoch 108/1000, Train Losses: 1.4380, Test Losses: 1.3819\n",
      "Epoch 109/1000, Train Losses: 1.4296, Test Losses: 1.3732\n",
      "Epoch 110/1000, Train Losses: 1.4211, Test Losses: 1.3644\n",
      "Epoch 111/1000, Train Losses: 1.4126, Test Losses: 1.3556\n",
      "Epoch 112/1000, Train Losses: 1.4041, Test Losses: 1.3468\n",
      "Epoch 113/1000, Train Losses: 1.3956, Test Losses: 1.3380\n",
      "Epoch 114/1000, Train Losses: 1.3871, Test Losses: 1.3292\n",
      "Epoch 115/1000, Train Losses: 1.3786, Test Losses: 1.3204\n",
      "Epoch 116/1000, Train Losses: 1.3701, Test Losses: 1.3116\n",
      "Epoch 117/1000, Train Losses: 1.3615, Test Losses: 1.3027\n",
      "Epoch 118/1000, Train Losses: 1.3530, Test Losses: 1.2939\n",
      "Epoch 119/1000, Train Losses: 1.3444, Test Losses: 1.2851\n",
      "Epoch 120/1000, Train Losses: 1.3358, Test Losses: 1.2762\n",
      "Epoch 121/1000, Train Losses: 1.3272, Test Losses: 1.2674\n",
      "Epoch 122/1000, Train Losses: 1.3186, Test Losses: 1.2586\n",
      "Epoch 123/1000, Train Losses: 1.3100, Test Losses: 1.2497\n",
      "Epoch 124/1000, Train Losses: 1.3014, Test Losses: 1.2409\n",
      "Epoch 125/1000, Train Losses: 1.2928, Test Losses: 1.2321\n",
      "Epoch 126/1000, Train Losses: 1.2842, Test Losses: 1.2232\n",
      "Epoch 127/1000, Train Losses: 1.2756, Test Losses: 1.2143\n",
      "Epoch 128/1000, Train Losses: 1.2670, Test Losses: 1.2055\n",
      "Epoch 129/1000, Train Losses: 1.2584, Test Losses: 1.1966\n",
      "Epoch 130/1000, Train Losses: 1.2498, Test Losses: 1.1877\n",
      "Epoch 131/1000, Train Losses: 1.2412, Test Losses: 1.1789\n",
      "Epoch 132/1000, Train Losses: 1.2327, Test Losses: 1.1700\n",
      "Epoch 133/1000, Train Losses: 1.2241, Test Losses: 1.1611\n",
      "Epoch 134/1000, Train Losses: 1.2156, Test Losses: 1.1523\n",
      "Epoch 135/1000, Train Losses: 1.2071, Test Losses: 1.1435\n",
      "Epoch 136/1000, Train Losses: 1.1986, Test Losses: 1.1348\n",
      "Epoch 137/1000, Train Losses: 1.1902, Test Losses: 1.1261\n",
      "Epoch 138/1000, Train Losses: 1.1818, Test Losses: 1.1175\n",
      "Epoch 139/1000, Train Losses: 1.1735, Test Losses: 1.1089\n",
      "Epoch 140/1000, Train Losses: 1.1651, Test Losses: 1.1004\n",
      "Epoch 141/1000, Train Losses: 1.1568, Test Losses: 1.0919\n",
      "Epoch 142/1000, Train Losses: 1.1486, Test Losses: 1.0835\n",
      "Epoch 143/1000, Train Losses: 1.1404, Test Losses: 1.0752\n",
      "Epoch 144/1000, Train Losses: 1.1322, Test Losses: 1.0669\n",
      "Epoch 145/1000, Train Losses: 1.1241, Test Losses: 1.0586\n",
      "Epoch 146/1000, Train Losses: 1.1161, Test Losses: 1.0505\n",
      "Epoch 147/1000, Train Losses: 1.1081, Test Losses: 1.0424\n",
      "Epoch 148/1000, Train Losses: 1.1001, Test Losses: 1.0344\n",
      "Epoch 149/1000, Train Losses: 1.0923, Test Losses: 1.0264\n",
      "Epoch 150/1000, Train Losses: 1.0845, Test Losses: 1.0186\n",
      "Epoch 151/1000, Train Losses: 1.0767, Test Losses: 1.0108\n",
      "Epoch 152/1000, Train Losses: 1.0691, Test Losses: 1.0030\n",
      "Epoch 153/1000, Train Losses: 1.0615, Test Losses: 0.9954\n",
      "Epoch 154/1000, Train Losses: 1.0539, Test Losses: 0.9877\n",
      "Epoch 155/1000, Train Losses: 1.0464, Test Losses: 0.9802\n",
      "Epoch 156/1000, Train Losses: 1.0389, Test Losses: 0.9728\n",
      "Epoch 157/1000, Train Losses: 1.0315, Test Losses: 0.9654\n",
      "Epoch 158/1000, Train Losses: 1.0242, Test Losses: 0.9581\n",
      "Epoch 159/1000, Train Losses: 1.0170, Test Losses: 0.9509\n",
      "Epoch 160/1000, Train Losses: 1.0098, Test Losses: 0.9437\n",
      "Epoch 161/1000, Train Losses: 1.0027, Test Losses: 0.9367\n",
      "Epoch 162/1000, Train Losses: 0.9957, Test Losses: 0.9298\n",
      "Epoch 163/1000, Train Losses: 0.9888, Test Losses: 0.9229\n",
      "Epoch 164/1000, Train Losses: 0.9819, Test Losses: 0.9162\n",
      "Epoch 165/1000, Train Losses: 0.9752, Test Losses: 0.9096\n",
      "Epoch 166/1000, Train Losses: 0.9685, Test Losses: 0.9031\n",
      "Epoch 167/1000, Train Losses: 0.9619, Test Losses: 0.8966\n",
      "Epoch 168/1000, Train Losses: 0.9554, Test Losses: 0.8903\n",
      "Epoch 169/1000, Train Losses: 0.9490, Test Losses: 0.8840\n",
      "Epoch 170/1000, Train Losses: 0.9427, Test Losses: 0.8779\n",
      "Epoch 171/1000, Train Losses: 0.9365, Test Losses: 0.8718\n",
      "Epoch 172/1000, Train Losses: 0.9303, Test Losses: 0.8659\n",
      "Epoch 173/1000, Train Losses: 0.9243, Test Losses: 0.8600\n",
      "Epoch 174/1000, Train Losses: 0.9183, Test Losses: 0.8542\n",
      "Epoch 175/1000, Train Losses: 0.9124, Test Losses: 0.8485\n",
      "Epoch 176/1000, Train Losses: 0.9066, Test Losses: 0.8429\n",
      "Epoch 177/1000, Train Losses: 0.9008, Test Losses: 0.8374\n",
      "Epoch 178/1000, Train Losses: 0.8952, Test Losses: 0.8320\n",
      "Epoch 179/1000, Train Losses: 0.8896, Test Losses: 0.8267\n",
      "Epoch 180/1000, Train Losses: 0.8841, Test Losses: 0.8215\n",
      "Epoch 181/1000, Train Losses: 0.8787, Test Losses: 0.8163\n",
      "Epoch 182/1000, Train Losses: 0.8734, Test Losses: 0.8113\n",
      "Epoch 183/1000, Train Losses: 0.8682, Test Losses: 0.8063\n",
      "Epoch 184/1000, Train Losses: 0.8630, Test Losses: 0.8014\n",
      "Epoch 185/1000, Train Losses: 0.8579, Test Losses: 0.7965\n",
      "Epoch 186/1000, Train Losses: 0.8529, Test Losses: 0.7918\n",
      "Epoch 187/1000, Train Losses: 0.8480, Test Losses: 0.7871\n",
      "Epoch 188/1000, Train Losses: 0.8431, Test Losses: 0.7826\n",
      "Epoch 189/1000, Train Losses: 0.8384, Test Losses: 0.7781\n",
      "Epoch 190/1000, Train Losses: 0.8337, Test Losses: 0.7736\n",
      "Epoch 191/1000, Train Losses: 0.8290, Test Losses: 0.7693\n",
      "Epoch 192/1000, Train Losses: 0.8245, Test Losses: 0.7650\n",
      "Epoch 193/1000, Train Losses: 0.8200, Test Losses: 0.7608\n",
      "Epoch 194/1000, Train Losses: 0.8155, Test Losses: 0.7567\n",
      "Epoch 195/1000, Train Losses: 0.8112, Test Losses: 0.7527\n",
      "Epoch 196/1000, Train Losses: 0.8069, Test Losses: 0.7487\n",
      "Epoch 197/1000, Train Losses: 0.8027, Test Losses: 0.7448\n",
      "Epoch 198/1000, Train Losses: 0.7985, Test Losses: 0.7410\n",
      "Epoch 199/1000, Train Losses: 0.7944, Test Losses: 0.7372\n",
      "Epoch 200/1000, Train Losses: 0.7904, Test Losses: 0.7335\n",
      "Epoch 201/1000, Train Losses: 0.7864, Test Losses: 0.7299\n",
      "Epoch 202/1000, Train Losses: 0.7825, Test Losses: 0.7263\n",
      "Epoch 203/1000, Train Losses: 0.7786, Test Losses: 0.7228\n",
      "Epoch 204/1000, Train Losses: 0.7748, Test Losses: 0.7194\n",
      "Epoch 205/1000, Train Losses: 0.7710, Test Losses: 0.7160\n",
      "Epoch 206/1000, Train Losses: 0.7674, Test Losses: 0.7126\n",
      "Epoch 207/1000, Train Losses: 0.7637, Test Losses: 0.7094\n",
      "Epoch 208/1000, Train Losses: 0.7601, Test Losses: 0.7061\n",
      "Epoch 209/1000, Train Losses: 0.7566, Test Losses: 0.7030\n",
      "Epoch 210/1000, Train Losses: 0.7531, Test Losses: 0.6998\n",
      "Epoch 211/1000, Train Losses: 0.7497, Test Losses: 0.6968\n",
      "Epoch 212/1000, Train Losses: 0.7463, Test Losses: 0.6937\n",
      "Epoch 213/1000, Train Losses: 0.7430, Test Losses: 0.6908\n",
      "Epoch 214/1000, Train Losses: 0.7397, Test Losses: 0.6879\n",
      "Epoch 215/1000, Train Losses: 0.7365, Test Losses: 0.6850\n",
      "Epoch 216/1000, Train Losses: 0.7333, Test Losses: 0.6822\n",
      "Epoch 217/1000, Train Losses: 0.7301, Test Losses: 0.6794\n",
      "Epoch 218/1000, Train Losses: 0.7270, Test Losses: 0.6766\n",
      "Epoch 219/1000, Train Losses: 0.7240, Test Losses: 0.6739\n",
      "Epoch 220/1000, Train Losses: 0.7210, Test Losses: 0.6713\n",
      "Epoch 221/1000, Train Losses: 0.7180, Test Losses: 0.6687\n",
      "Epoch 222/1000, Train Losses: 0.7151, Test Losses: 0.6661\n",
      "Epoch 223/1000, Train Losses: 0.7122, Test Losses: 0.6636\n",
      "Epoch 224/1000, Train Losses: 0.7093, Test Losses: 0.6611\n",
      "Epoch 225/1000, Train Losses: 0.7065, Test Losses: 0.6586\n",
      "Epoch 226/1000, Train Losses: 0.7037, Test Losses: 0.6562\n",
      "Epoch 227/1000, Train Losses: 0.7010, Test Losses: 0.6539\n",
      "Epoch 228/1000, Train Losses: 0.6983, Test Losses: 0.6515\n",
      "Epoch 229/1000, Train Losses: 0.6956, Test Losses: 0.6492\n",
      "Epoch 230/1000, Train Losses: 0.6930, Test Losses: 0.6470\n",
      "Epoch 231/1000, Train Losses: 0.6904, Test Losses: 0.6447\n",
      "Epoch 232/1000, Train Losses: 0.6878, Test Losses: 0.6425\n",
      "Epoch 233/1000, Train Losses: 0.6853, Test Losses: 0.6403\n",
      "Epoch 234/1000, Train Losses: 0.6828, Test Losses: 0.6382\n",
      "Epoch 235/1000, Train Losses: 0.6803, Test Losses: 0.6361\n",
      "Epoch 236/1000, Train Losses: 0.6778, Test Losses: 0.6340\n",
      "Epoch 237/1000, Train Losses: 0.6754, Test Losses: 0.6320\n",
      "Epoch 238/1000, Train Losses: 0.6730, Test Losses: 0.6299\n",
      "Epoch 239/1000, Train Losses: 0.6706, Test Losses: 0.6279\n",
      "Epoch 240/1000, Train Losses: 0.6682, Test Losses: 0.6259\n",
      "Epoch 241/1000, Train Losses: 0.6659, Test Losses: 0.6240\n",
      "Epoch 242/1000, Train Losses: 0.6636, Test Losses: 0.6220\n",
      "Epoch 243/1000, Train Losses: 0.6613, Test Losses: 0.6201\n",
      "Epoch 244/1000, Train Losses: 0.6591, Test Losses: 0.6182\n",
      "Epoch 245/1000, Train Losses: 0.6569, Test Losses: 0.6164\n",
      "Epoch 246/1000, Train Losses: 0.6547, Test Losses: 0.6145\n",
      "Epoch 247/1000, Train Losses: 0.6525, Test Losses: 0.6127\n",
      "Epoch 248/1000, Train Losses: 0.6504, Test Losses: 0.6109\n",
      "Epoch 249/1000, Train Losses: 0.6482, Test Losses: 0.6092\n",
      "Epoch 250/1000, Train Losses: 0.6462, Test Losses: 0.6074\n",
      "Epoch 251/1000, Train Losses: 0.6441, Test Losses: 0.6057\n",
      "Epoch 252/1000, Train Losses: 0.6420, Test Losses: 0.6040\n",
      "Epoch 253/1000, Train Losses: 0.6400, Test Losses: 0.6023\n",
      "Epoch 254/1000, Train Losses: 0.6380, Test Losses: 0.6007\n",
      "Epoch 255/1000, Train Losses: 0.6361, Test Losses: 0.5991\n",
      "Epoch 256/1000, Train Losses: 0.6341, Test Losses: 0.5974\n",
      "Epoch 257/1000, Train Losses: 0.6322, Test Losses: 0.5958\n",
      "Epoch 258/1000, Train Losses: 0.6303, Test Losses: 0.5943\n",
      "Epoch 259/1000, Train Losses: 0.6284, Test Losses: 0.5927\n",
      "Epoch 260/1000, Train Losses: 0.6265, Test Losses: 0.5912\n",
      "Epoch 261/1000, Train Losses: 0.6247, Test Losses: 0.5896\n",
      "Epoch 262/1000, Train Losses: 0.6228, Test Losses: 0.5881\n",
      "Epoch 263/1000, Train Losses: 0.6210, Test Losses: 0.5867\n",
      "Epoch 264/1000, Train Losses: 0.6192, Test Losses: 0.5852\n",
      "Epoch 265/1000, Train Losses: 0.6175, Test Losses: 0.5837\n",
      "Epoch 266/1000, Train Losses: 0.6157, Test Losses: 0.5823\n",
      "Epoch 267/1000, Train Losses: 0.6140, Test Losses: 0.5809\n",
      "Epoch 268/1000, Train Losses: 0.6122, Test Losses: 0.5795\n",
      "Epoch 269/1000, Train Losses: 0.6105, Test Losses: 0.5781\n",
      "Epoch 270/1000, Train Losses: 0.6088, Test Losses: 0.5767\n",
      "Epoch 271/1000, Train Losses: 0.6071, Test Losses: 0.5754\n",
      "Epoch 272/1000, Train Losses: 0.6055, Test Losses: 0.5740\n",
      "Epoch 273/1000, Train Losses: 0.6038, Test Losses: 0.5727\n",
      "Epoch 274/1000, Train Losses: 0.6022, Test Losses: 0.5714\n",
      "Epoch 275/1000, Train Losses: 0.6006, Test Losses: 0.5701\n",
      "Epoch 276/1000, Train Losses: 0.5990, Test Losses: 0.5688\n",
      "Epoch 277/1000, Train Losses: 0.5974, Test Losses: 0.5675\n",
      "Epoch 278/1000, Train Losses: 0.5958, Test Losses: 0.5663\n",
      "Epoch 279/1000, Train Losses: 0.5943, Test Losses: 0.5650\n",
      "Epoch 280/1000, Train Losses: 0.5927, Test Losses: 0.5638\n",
      "Epoch 281/1000, Train Losses: 0.5912, Test Losses: 0.5626\n",
      "Epoch 282/1000, Train Losses: 0.5897, Test Losses: 0.5614\n",
      "Epoch 283/1000, Train Losses: 0.5882, Test Losses: 0.5602\n",
      "Epoch 284/1000, Train Losses: 0.5868, Test Losses: 0.5590\n",
      "Epoch 285/1000, Train Losses: 0.5853, Test Losses: 0.5578\n",
      "Epoch 286/1000, Train Losses: 0.5838, Test Losses: 0.5567\n",
      "Epoch 287/1000, Train Losses: 0.5824, Test Losses: 0.5555\n",
      "Epoch 288/1000, Train Losses: 0.5810, Test Losses: 0.5544\n",
      "Epoch 289/1000, Train Losses: 0.5796, Test Losses: 0.5532\n",
      "Epoch 290/1000, Train Losses: 0.5782, Test Losses: 0.5521\n",
      "Epoch 291/1000, Train Losses: 0.5768, Test Losses: 0.5510\n",
      "Epoch 292/1000, Train Losses: 0.5754, Test Losses: 0.5499\n",
      "Epoch 293/1000, Train Losses: 0.5741, Test Losses: 0.5488\n",
      "Epoch 294/1000, Train Losses: 0.5727, Test Losses: 0.5477\n",
      "Epoch 295/1000, Train Losses: 0.5714, Test Losses: 0.5467\n",
      "Epoch 296/1000, Train Losses: 0.5701, Test Losses: 0.5456\n",
      "Epoch 297/1000, Train Losses: 0.5688, Test Losses: 0.5446\n",
      "Epoch 298/1000, Train Losses: 0.5675, Test Losses: 0.5436\n",
      "Epoch 299/1000, Train Losses: 0.5662, Test Losses: 0.5425\n",
      "Epoch 300/1000, Train Losses: 0.5649, Test Losses: 0.5415\n",
      "Epoch 301/1000, Train Losses: 0.5637, Test Losses: 0.5405\n",
      "Epoch 302/1000, Train Losses: 0.5624, Test Losses: 0.5395\n",
      "Epoch 303/1000, Train Losses: 0.5612, Test Losses: 0.5385\n",
      "Epoch 304/1000, Train Losses: 0.5600, Test Losses: 0.5376\n",
      "Epoch 305/1000, Train Losses: 0.5587, Test Losses: 0.5366\n",
      "Epoch 306/1000, Train Losses: 0.5575, Test Losses: 0.5357\n",
      "Epoch 307/1000, Train Losses: 0.5563, Test Losses: 0.5347\n",
      "Epoch 308/1000, Train Losses: 0.5551, Test Losses: 0.5338\n",
      "Epoch 309/1000, Train Losses: 0.5540, Test Losses: 0.5329\n",
      "Epoch 310/1000, Train Losses: 0.5528, Test Losses: 0.5319\n",
      "Epoch 311/1000, Train Losses: 0.5516, Test Losses: 0.5310\n",
      "Epoch 312/1000, Train Losses: 0.5505, Test Losses: 0.5301\n",
      "Epoch 313/1000, Train Losses: 0.5493, Test Losses: 0.5292\n",
      "Epoch 314/1000, Train Losses: 0.5482, Test Losses: 0.5284\n",
      "Epoch 315/1000, Train Losses: 0.5471, Test Losses: 0.5275\n",
      "Epoch 316/1000, Train Losses: 0.5459, Test Losses: 0.5266\n",
      "Epoch 317/1000, Train Losses: 0.5448, Test Losses: 0.5258\n",
      "Epoch 318/1000, Train Losses: 0.5437, Test Losses: 0.5249\n",
      "Epoch 319/1000, Train Losses: 0.5426, Test Losses: 0.5241\n",
      "Epoch 320/1000, Train Losses: 0.5415, Test Losses: 0.5233\n",
      "Epoch 321/1000, Train Losses: 0.5405, Test Losses: 0.5224\n",
      "Epoch 322/1000, Train Losses: 0.5394, Test Losses: 0.5216\n",
      "Epoch 323/1000, Train Losses: 0.5383, Test Losses: 0.5208\n",
      "Epoch 324/1000, Train Losses: 0.5373, Test Losses: 0.5200\n",
      "Epoch 325/1000, Train Losses: 0.5362, Test Losses: 0.5192\n",
      "Epoch 326/1000, Train Losses: 0.5352, Test Losses: 0.5185\n",
      "Epoch 327/1000, Train Losses: 0.5342, Test Losses: 0.5177\n",
      "Epoch 328/1000, Train Losses: 0.5332, Test Losses: 0.5169\n",
      "Epoch 329/1000, Train Losses: 0.5321, Test Losses: 0.5162\n",
      "Epoch 330/1000, Train Losses: 0.5311, Test Losses: 0.5154\n",
      "Epoch 331/1000, Train Losses: 0.5301, Test Losses: 0.5146\n",
      "Epoch 332/1000, Train Losses: 0.5291, Test Losses: 0.5139\n",
      "Epoch 333/1000, Train Losses: 0.5282, Test Losses: 0.5132\n",
      "Epoch 334/1000, Train Losses: 0.5272, Test Losses: 0.5124\n",
      "Epoch 335/1000, Train Losses: 0.5262, Test Losses: 0.5117\n",
      "Epoch 336/1000, Train Losses: 0.5252, Test Losses: 0.5110\n",
      "Epoch 337/1000, Train Losses: 0.5243, Test Losses: 0.5103\n",
      "Epoch 338/1000, Train Losses: 0.5233, Test Losses: 0.5096\n",
      "Epoch 339/1000, Train Losses: 0.5224, Test Losses: 0.5089\n",
      "Epoch 340/1000, Train Losses: 0.5214, Test Losses: 0.5082\n",
      "Epoch 341/1000, Train Losses: 0.5205, Test Losses: 0.5075\n",
      "Epoch 342/1000, Train Losses: 0.5196, Test Losses: 0.5068\n",
      "Epoch 343/1000, Train Losses: 0.5187, Test Losses: 0.5061\n",
      "Epoch 344/1000, Train Losses: 0.5178, Test Losses: 0.5054\n",
      "Epoch 345/1000, Train Losses: 0.5169, Test Losses: 0.5048\n",
      "Epoch 346/1000, Train Losses: 0.5160, Test Losses: 0.5041\n",
      "Epoch 347/1000, Train Losses: 0.5151, Test Losses: 0.5034\n",
      "Epoch 348/1000, Train Losses: 0.5142, Test Losses: 0.5027\n",
      "Epoch 349/1000, Train Losses: 0.5133, Test Losses: 0.5021\n",
      "Epoch 350/1000, Train Losses: 0.5124, Test Losses: 0.5014\n",
      "Epoch 351/1000, Train Losses: 0.5116, Test Losses: 0.5008\n",
      "Epoch 352/1000, Train Losses: 0.5107, Test Losses: 0.5001\n",
      "Epoch 353/1000, Train Losses: 0.5099, Test Losses: 0.4995\n",
      "Epoch 354/1000, Train Losses: 0.5090, Test Losses: 0.4988\n",
      "Epoch 355/1000, Train Losses: 0.5082, Test Losses: 0.4982\n",
      "Epoch 356/1000, Train Losses: 0.5073, Test Losses: 0.4976\n",
      "Epoch 357/1000, Train Losses: 0.5065, Test Losses: 0.4969\n",
      "Epoch 358/1000, Train Losses: 0.5057, Test Losses: 0.4963\n",
      "Epoch 359/1000, Train Losses: 0.5048, Test Losses: 0.4957\n",
      "Epoch 360/1000, Train Losses: 0.5040, Test Losses: 0.4951\n",
      "Epoch 361/1000, Train Losses: 0.5032, Test Losses: 0.4945\n",
      "Epoch 362/1000, Train Losses: 0.5024, Test Losses: 0.4939\n",
      "Epoch 363/1000, Train Losses: 0.5016, Test Losses: 0.4932\n",
      "Epoch 364/1000, Train Losses: 0.5008, Test Losses: 0.4926\n",
      "Epoch 365/1000, Train Losses: 0.5000, Test Losses: 0.4920\n",
      "Epoch 366/1000, Train Losses: 0.4992, Test Losses: 0.4915\n",
      "Epoch 367/1000, Train Losses: 0.4984, Test Losses: 0.4909\n",
      "Epoch 368/1000, Train Losses: 0.4976, Test Losses: 0.4903\n",
      "Epoch 369/1000, Train Losses: 0.4968, Test Losses: 0.4897\n",
      "Epoch 370/1000, Train Losses: 0.4961, Test Losses: 0.4891\n",
      "Epoch 371/1000, Train Losses: 0.4953, Test Losses: 0.4885\n",
      "Epoch 372/1000, Train Losses: 0.4945, Test Losses: 0.4879\n",
      "Epoch 373/1000, Train Losses: 0.4938, Test Losses: 0.4874\n",
      "Epoch 374/1000, Train Losses: 0.4930, Test Losses: 0.4868\n",
      "Epoch 375/1000, Train Losses: 0.4922, Test Losses: 0.4862\n",
      "Epoch 376/1000, Train Losses: 0.4915, Test Losses: 0.4856\n",
      "Epoch 377/1000, Train Losses: 0.4907, Test Losses: 0.4851\n",
      "Epoch 378/1000, Train Losses: 0.4900, Test Losses: 0.4845\n",
      "Epoch 379/1000, Train Losses: 0.4893, Test Losses: 0.4840\n",
      "Epoch 380/1000, Train Losses: 0.4885, Test Losses: 0.4834\n",
      "Epoch 381/1000, Train Losses: 0.4878, Test Losses: 0.4829\n",
      "Epoch 382/1000, Train Losses: 0.4871, Test Losses: 0.4823\n",
      "Epoch 383/1000, Train Losses: 0.4864, Test Losses: 0.4818\n",
      "Epoch 384/1000, Train Losses: 0.4856, Test Losses: 0.4813\n",
      "Epoch 385/1000, Train Losses: 0.4849, Test Losses: 0.4807\n",
      "Epoch 386/1000, Train Losses: 0.4842, Test Losses: 0.4802\n",
      "Epoch 387/1000, Train Losses: 0.4835, Test Losses: 0.4797\n",
      "Epoch 388/1000, Train Losses: 0.4828, Test Losses: 0.4792\n",
      "Epoch 389/1000, Train Losses: 0.4821, Test Losses: 0.4786\n",
      "Epoch 390/1000, Train Losses: 0.4814, Test Losses: 0.4781\n",
      "Epoch 391/1000, Train Losses: 0.4807, Test Losses: 0.4776\n",
      "Epoch 392/1000, Train Losses: 0.4800, Test Losses: 0.4771\n",
      "Epoch 393/1000, Train Losses: 0.4793, Test Losses: 0.4766\n",
      "Epoch 394/1000, Train Losses: 0.4787, Test Losses: 0.4761\n",
      "Epoch 395/1000, Train Losses: 0.4780, Test Losses: 0.4756\n",
      "Epoch 396/1000, Train Losses: 0.4773, Test Losses: 0.4751\n",
      "Epoch 397/1000, Train Losses: 0.4766, Test Losses: 0.4746\n",
      "Epoch 398/1000, Train Losses: 0.4759, Test Losses: 0.4741\n",
      "Epoch 399/1000, Train Losses: 0.4753, Test Losses: 0.4737\n",
      "Epoch 400/1000, Train Losses: 0.4746, Test Losses: 0.4732\n",
      "Epoch 401/1000, Train Losses: 0.4740, Test Losses: 0.4727\n",
      "Epoch 402/1000, Train Losses: 0.4733, Test Losses: 0.4722\n",
      "Epoch 403/1000, Train Losses: 0.4726, Test Losses: 0.4718\n",
      "Epoch 404/1000, Train Losses: 0.4720, Test Losses: 0.4713\n",
      "Epoch 405/1000, Train Losses: 0.4713, Test Losses: 0.4708\n",
      "Epoch 406/1000, Train Losses: 0.4707, Test Losses: 0.4704\n",
      "Epoch 407/1000, Train Losses: 0.4700, Test Losses: 0.4699\n",
      "Epoch 408/1000, Train Losses: 0.4694, Test Losses: 0.4694\n",
      "Epoch 409/1000, Train Losses: 0.4688, Test Losses: 0.4690\n",
      "Epoch 410/1000, Train Losses: 0.4681, Test Losses: 0.4685\n",
      "Epoch 411/1000, Train Losses: 0.4675, Test Losses: 0.4680\n",
      "Epoch 412/1000, Train Losses: 0.4669, Test Losses: 0.4676\n",
      "Epoch 413/1000, Train Losses: 0.4662, Test Losses: 0.4671\n",
      "Epoch 414/1000, Train Losses: 0.4656, Test Losses: 0.4667\n",
      "Epoch 415/1000, Train Losses: 0.4650, Test Losses: 0.4662\n",
      "Epoch 416/1000, Train Losses: 0.4644, Test Losses: 0.4658\n",
      "Epoch 417/1000, Train Losses: 0.4638, Test Losses: 0.4653\n",
      "Epoch 418/1000, Train Losses: 0.4631, Test Losses: 0.4649\n",
      "Epoch 419/1000, Train Losses: 0.4625, Test Losses: 0.4645\n",
      "Epoch 420/1000, Train Losses: 0.4619, Test Losses: 0.4640\n",
      "Epoch 421/1000, Train Losses: 0.4613, Test Losses: 0.4636\n",
      "Epoch 422/1000, Train Losses: 0.4607, Test Losses: 0.4632\n",
      "Epoch 423/1000, Train Losses: 0.4601, Test Losses: 0.4627\n",
      "Epoch 424/1000, Train Losses: 0.4595, Test Losses: 0.4623\n",
      "Epoch 425/1000, Train Losses: 0.4589, Test Losses: 0.4619\n",
      "Epoch 426/1000, Train Losses: 0.4583, Test Losses: 0.4615\n",
      "Epoch 427/1000, Train Losses: 0.4578, Test Losses: 0.4610\n",
      "Epoch 428/1000, Train Losses: 0.4572, Test Losses: 0.4606\n",
      "Epoch 429/1000, Train Losses: 0.4566, Test Losses: 0.4602\n",
      "Epoch 430/1000, Train Losses: 0.4560, Test Losses: 0.4598\n",
      "Epoch 431/1000, Train Losses: 0.4554, Test Losses: 0.4594\n",
      "Epoch 432/1000, Train Losses: 0.4548, Test Losses: 0.4590\n",
      "Epoch 433/1000, Train Losses: 0.4543, Test Losses: 0.4586\n",
      "Epoch 434/1000, Train Losses: 0.4537, Test Losses: 0.4582\n",
      "Epoch 435/1000, Train Losses: 0.4531, Test Losses: 0.4578\n",
      "Epoch 436/1000, Train Losses: 0.4526, Test Losses: 0.4574\n",
      "Epoch 437/1000, Train Losses: 0.4520, Test Losses: 0.4570\n",
      "Epoch 438/1000, Train Losses: 0.4514, Test Losses: 0.4566\n",
      "Epoch 439/1000, Train Losses: 0.4509, Test Losses: 0.4562\n",
      "Epoch 440/1000, Train Losses: 0.4503, Test Losses: 0.4559\n",
      "Epoch 441/1000, Train Losses: 0.4498, Test Losses: 0.4555\n",
      "Epoch 442/1000, Train Losses: 0.4492, Test Losses: 0.4551\n",
      "Epoch 443/1000, Train Losses: 0.4487, Test Losses: 0.4547\n",
      "Epoch 444/1000, Train Losses: 0.4481, Test Losses: 0.4543\n",
      "Epoch 445/1000, Train Losses: 0.4476, Test Losses: 0.4540\n",
      "Epoch 446/1000, Train Losses: 0.4470, Test Losses: 0.4536\n",
      "Epoch 447/1000, Train Losses: 0.4465, Test Losses: 0.4532\n",
      "Epoch 448/1000, Train Losses: 0.4460, Test Losses: 0.4528\n",
      "Epoch 449/1000, Train Losses: 0.4454, Test Losses: 0.4525\n",
      "Epoch 450/1000, Train Losses: 0.4449, Test Losses: 0.4521\n",
      "Epoch 451/1000, Train Losses: 0.4444, Test Losses: 0.4517\n",
      "Epoch 452/1000, Train Losses: 0.4438, Test Losses: 0.4514\n",
      "Epoch 453/1000, Train Losses: 0.4433, Test Losses: 0.4510\n",
      "Epoch 454/1000, Train Losses: 0.4428, Test Losses: 0.4507\n",
      "Epoch 455/1000, Train Losses: 0.4423, Test Losses: 0.4503\n",
      "Epoch 456/1000, Train Losses: 0.4418, Test Losses: 0.4500\n",
      "Epoch 457/1000, Train Losses: 0.4412, Test Losses: 0.4496\n",
      "Epoch 458/1000, Train Losses: 0.4407, Test Losses: 0.4493\n",
      "Epoch 459/1000, Train Losses: 0.4402, Test Losses: 0.4489\n",
      "Epoch 460/1000, Train Losses: 0.4397, Test Losses: 0.4486\n",
      "Epoch 461/1000, Train Losses: 0.4392, Test Losses: 0.4483\n",
      "Epoch 462/1000, Train Losses: 0.4387, Test Losses: 0.4479\n",
      "Epoch 463/1000, Train Losses: 0.4382, Test Losses: 0.4476\n",
      "Epoch 464/1000, Train Losses: 0.4377, Test Losses: 0.4473\n",
      "Epoch 465/1000, Train Losses: 0.4372, Test Losses: 0.4470\n",
      "Epoch 466/1000, Train Losses: 0.4367, Test Losses: 0.4466\n",
      "Epoch 467/1000, Train Losses: 0.4362, Test Losses: 0.4463\n",
      "Epoch 468/1000, Train Losses: 0.4358, Test Losses: 0.4460\n",
      "Epoch 469/1000, Train Losses: 0.4353, Test Losses: 0.4457\n",
      "Epoch 470/1000, Train Losses: 0.4348, Test Losses: 0.4454\n",
      "Epoch 471/1000, Train Losses: 0.4343, Test Losses: 0.4451\n",
      "Epoch 472/1000, Train Losses: 0.4339, Test Losses: 0.4448\n",
      "Epoch 473/1000, Train Losses: 0.4334, Test Losses: 0.4445\n",
      "Epoch 474/1000, Train Losses: 0.4329, Test Losses: 0.4442\n",
      "Epoch 475/1000, Train Losses: 0.4324, Test Losses: 0.4439\n",
      "Epoch 476/1000, Train Losses: 0.4320, Test Losses: 0.4436\n",
      "Epoch 477/1000, Train Losses: 0.4315, Test Losses: 0.4433\n",
      "Epoch 478/1000, Train Losses: 0.4310, Test Losses: 0.4430\n",
      "Epoch 479/1000, Train Losses: 0.4306, Test Losses: 0.4427\n",
      "Epoch 480/1000, Train Losses: 0.4301, Test Losses: 0.4424\n",
      "Epoch 481/1000, Train Losses: 0.4297, Test Losses: 0.4421\n",
      "Epoch 482/1000, Train Losses: 0.4292, Test Losses: 0.4419\n",
      "Epoch 483/1000, Train Losses: 0.4288, Test Losses: 0.4416\n",
      "Epoch 484/1000, Train Losses: 0.4283, Test Losses: 0.4413\n",
      "Epoch 485/1000, Train Losses: 0.4279, Test Losses: 0.4410\n",
      "Epoch 486/1000, Train Losses: 0.4274, Test Losses: 0.4407\n",
      "Epoch 487/1000, Train Losses: 0.4270, Test Losses: 0.4405\n",
      "Epoch 488/1000, Train Losses: 0.4265, Test Losses: 0.4402\n",
      "Epoch 489/1000, Train Losses: 0.4261, Test Losses: 0.4399\n",
      "Epoch 490/1000, Train Losses: 0.4256, Test Losses: 0.4397\n",
      "Epoch 491/1000, Train Losses: 0.4252, Test Losses: 0.4394\n",
      "Epoch 492/1000, Train Losses: 0.4248, Test Losses: 0.4391\n",
      "Epoch 493/1000, Train Losses: 0.4243, Test Losses: 0.4389\n",
      "Epoch 494/1000, Train Losses: 0.4239, Test Losses: 0.4386\n",
      "Epoch 495/1000, Train Losses: 0.4234, Test Losses: 0.4384\n",
      "Epoch 496/1000, Train Losses: 0.4230, Test Losses: 0.4381\n",
      "Epoch 497/1000, Train Losses: 0.4226, Test Losses: 0.4378\n",
      "Epoch 498/1000, Train Losses: 0.4222, Test Losses: 0.4376\n",
      "Epoch 499/1000, Train Losses: 0.4217, Test Losses: 0.4373\n",
      "Epoch 500/1000, Train Losses: 0.4213, Test Losses: 0.4371\n",
      "Epoch 501/1000, Train Losses: 0.4209, Test Losses: 0.4368\n",
      "Epoch 502/1000, Train Losses: 0.4204, Test Losses: 0.4366\n",
      "Epoch 503/1000, Train Losses: 0.4200, Test Losses: 0.4363\n",
      "Epoch 504/1000, Train Losses: 0.4196, Test Losses: 0.4361\n",
      "Epoch 505/1000, Train Losses: 0.4192, Test Losses: 0.4359\n",
      "Epoch 506/1000, Train Losses: 0.4188, Test Losses: 0.4356\n",
      "Epoch 507/1000, Train Losses: 0.4183, Test Losses: 0.4354\n",
      "Epoch 508/1000, Train Losses: 0.4179, Test Losses: 0.4352\n",
      "Epoch 509/1000, Train Losses: 0.4175, Test Losses: 0.4349\n",
      "Epoch 510/1000, Train Losses: 0.4171, Test Losses: 0.4347\n",
      "Epoch 511/1000, Train Losses: 0.4167, Test Losses: 0.4345\n",
      "Epoch 512/1000, Train Losses: 0.4163, Test Losses: 0.4342\n",
      "Epoch 513/1000, Train Losses: 0.4159, Test Losses: 0.4340\n",
      "Epoch 514/1000, Train Losses: 0.4155, Test Losses: 0.4338\n",
      "Epoch 515/1000, Train Losses: 0.4151, Test Losses: 0.4336\n",
      "Epoch 516/1000, Train Losses: 0.4147, Test Losses: 0.4334\n",
      "Epoch 517/1000, Train Losses: 0.4143, Test Losses: 0.4331\n",
      "Epoch 518/1000, Train Losses: 0.4139, Test Losses: 0.4329\n",
      "Epoch 519/1000, Train Losses: 0.4135, Test Losses: 0.4327\n",
      "Epoch 520/1000, Train Losses: 0.4131, Test Losses: 0.4325\n",
      "Epoch 521/1000, Train Losses: 0.4127, Test Losses: 0.4323\n",
      "Epoch 522/1000, Train Losses: 0.4123, Test Losses: 0.4321\n",
      "Epoch 523/1000, Train Losses: 0.4119, Test Losses: 0.4319\n",
      "Epoch 524/1000, Train Losses: 0.4116, Test Losses: 0.4317\n",
      "Epoch 525/1000, Train Losses: 0.4112, Test Losses: 0.4315\n",
      "Epoch 526/1000, Train Losses: 0.4108, Test Losses: 0.4313\n",
      "Epoch 527/1000, Train Losses: 0.4104, Test Losses: 0.4311\n",
      "Epoch 528/1000, Train Losses: 0.4100, Test Losses: 0.4309\n",
      "Epoch 529/1000, Train Losses: 0.4097, Test Losses: 0.4307\n",
      "Epoch 530/1000, Train Losses: 0.4093, Test Losses: 0.4305\n",
      "Epoch 531/1000, Train Losses: 0.4089, Test Losses: 0.4303\n",
      "Epoch 532/1000, Train Losses: 0.4086, Test Losses: 0.4301\n",
      "Epoch 533/1000, Train Losses: 0.4082, Test Losses: 0.4299\n",
      "Epoch 534/1000, Train Losses: 0.4078, Test Losses: 0.4297\n",
      "Epoch 535/1000, Train Losses: 0.4075, Test Losses: 0.4295\n",
      "Epoch 536/1000, Train Losses: 0.4071, Test Losses: 0.4293\n",
      "Epoch 537/1000, Train Losses: 0.4067, Test Losses: 0.4291\n",
      "Epoch 538/1000, Train Losses: 0.4064, Test Losses: 0.4289\n",
      "Epoch 539/1000, Train Losses: 0.4060, Test Losses: 0.4288\n",
      "Epoch 540/1000, Train Losses: 0.4057, Test Losses: 0.4286\n",
      "Epoch 541/1000, Train Losses: 0.4053, Test Losses: 0.4284\n",
      "Epoch 542/1000, Train Losses: 0.4050, Test Losses: 0.4282\n",
      "Epoch 543/1000, Train Losses: 0.4046, Test Losses: 0.4280\n",
      "Epoch 544/1000, Train Losses: 0.4043, Test Losses: 0.4279\n",
      "Epoch 545/1000, Train Losses: 0.4039, Test Losses: 0.4277\n",
      "Epoch 546/1000, Train Losses: 0.4036, Test Losses: 0.4275\n",
      "Epoch 547/1000, Train Losses: 0.4032, Test Losses: 0.4273\n",
      "Epoch 548/1000, Train Losses: 0.4029, Test Losses: 0.4271\n",
      "Epoch 549/1000, Train Losses: 0.4026, Test Losses: 0.4270\n",
      "Epoch 550/1000, Train Losses: 0.4022, Test Losses: 0.4268\n",
      "Epoch 551/1000, Train Losses: 0.4019, Test Losses: 0.4266\n",
      "Epoch 552/1000, Train Losses: 0.4016, Test Losses: 0.4264\n",
      "Epoch 553/1000, Train Losses: 0.4012, Test Losses: 0.4263\n",
      "Epoch 554/1000, Train Losses: 0.4009, Test Losses: 0.4261\n",
      "Epoch 555/1000, Train Losses: 0.4006, Test Losses: 0.4259\n",
      "Epoch 556/1000, Train Losses: 0.4002, Test Losses: 0.4258\n",
      "Epoch 557/1000, Train Losses: 0.3999, Test Losses: 0.4256\n",
      "Epoch 558/1000, Train Losses: 0.3996, Test Losses: 0.4254\n",
      "Epoch 559/1000, Train Losses: 0.3992, Test Losses: 0.4253\n",
      "Epoch 560/1000, Train Losses: 0.3989, Test Losses: 0.4251\n",
      "Epoch 561/1000, Train Losses: 0.3986, Test Losses: 0.4250\n",
      "Epoch 562/1000, Train Losses: 0.3983, Test Losses: 0.4248\n",
      "Epoch 563/1000, Train Losses: 0.3980, Test Losses: 0.4247\n",
      "Epoch 564/1000, Train Losses: 0.3976, Test Losses: 0.4245\n",
      "Epoch 565/1000, Train Losses: 0.3973, Test Losses: 0.4244\n",
      "Epoch 566/1000, Train Losses: 0.3970, Test Losses: 0.4242\n",
      "Epoch 567/1000, Train Losses: 0.3967, Test Losses: 0.4241\n",
      "Epoch 568/1000, Train Losses: 0.3964, Test Losses: 0.4239\n",
      "Epoch 569/1000, Train Losses: 0.3961, Test Losses: 0.4238\n",
      "Epoch 570/1000, Train Losses: 0.3958, Test Losses: 0.4236\n",
      "Epoch 571/1000, Train Losses: 0.3955, Test Losses: 0.4235\n",
      "Epoch 572/1000, Train Losses: 0.3951, Test Losses: 0.4233\n",
      "Epoch 573/1000, Train Losses: 0.3948, Test Losses: 0.4232\n",
      "Epoch 574/1000, Train Losses: 0.3945, Test Losses: 0.4231\n",
      "Epoch 575/1000, Train Losses: 0.3942, Test Losses: 0.4229\n",
      "Epoch 576/1000, Train Losses: 0.3939, Test Losses: 0.4228\n",
      "Epoch 577/1000, Train Losses: 0.3936, Test Losses: 0.4226\n",
      "Epoch 578/1000, Train Losses: 0.3933, Test Losses: 0.4225\n",
      "Epoch 579/1000, Train Losses: 0.3930, Test Losses: 0.4224\n",
      "Epoch 580/1000, Train Losses: 0.3927, Test Losses: 0.4223\n",
      "Epoch 581/1000, Train Losses: 0.3924, Test Losses: 0.4222\n",
      "Epoch 582/1000, Train Losses: 0.3921, Test Losses: 0.4220\n",
      "Epoch 583/1000, Train Losses: 0.3918, Test Losses: 0.4219\n",
      "Epoch 584/1000, Train Losses: 0.3915, Test Losses: 0.4218\n",
      "Epoch 585/1000, Train Losses: 0.3913, Test Losses: 0.4217\n",
      "Epoch 586/1000, Train Losses: 0.3910, Test Losses: 0.4216\n",
      "Epoch 587/1000, Train Losses: 0.3907, Test Losses: 0.4214\n",
      "Epoch 588/1000, Train Losses: 0.3904, Test Losses: 0.4213\n",
      "Epoch 589/1000, Train Losses: 0.3901, Test Losses: 0.4212\n",
      "Epoch 590/1000, Train Losses: 0.3898, Test Losses: 0.4211\n",
      "Epoch 591/1000, Train Losses: 0.3896, Test Losses: 0.4209\n",
      "Epoch 592/1000, Train Losses: 0.3893, Test Losses: 0.4208\n",
      "Epoch 593/1000, Train Losses: 0.3890, Test Losses: 0.4206\n",
      "Epoch 594/1000, Train Losses: 0.3887, Test Losses: 0.4205\n",
      "Epoch 595/1000, Train Losses: 0.3885, Test Losses: 0.4203\n",
      "Epoch 596/1000, Train Losses: 0.3882, Test Losses: 0.4202\n",
      "Epoch 597/1000, Train Losses: 0.3879, Test Losses: 0.4200\n",
      "Epoch 598/1000, Train Losses: 0.3876, Test Losses: 0.4199\n",
      "Epoch 599/1000, Train Losses: 0.3874, Test Losses: 0.4197\n",
      "Epoch 600/1000, Train Losses: 0.3871, Test Losses: 0.4196\n",
      "Epoch 601/1000, Train Losses: 0.3868, Test Losses: 0.4194\n",
      "Epoch 602/1000, Train Losses: 0.3866, Test Losses: 0.4193\n",
      "Epoch 603/1000, Train Losses: 0.3863, Test Losses: 0.4191\n",
      "Epoch 604/1000, Train Losses: 0.3860, Test Losses: 0.4190\n",
      "Epoch 605/1000, Train Losses: 0.3858, Test Losses: 0.4188\n",
      "Epoch 606/1000, Train Losses: 0.3855, Test Losses: 0.4187\n",
      "Epoch 607/1000, Train Losses: 0.3853, Test Losses: 0.4185\n",
      "Epoch 608/1000, Train Losses: 0.3850, Test Losses: 0.4184\n",
      "Epoch 609/1000, Train Losses: 0.3847, Test Losses: 0.4182\n",
      "Epoch 610/1000, Train Losses: 0.3845, Test Losses: 0.4181\n",
      "Epoch 611/1000, Train Losses: 0.3842, Test Losses: 0.4179\n",
      "Epoch 612/1000, Train Losses: 0.3840, Test Losses: 0.4178\n",
      "Epoch 613/1000, Train Losses: 0.3837, Test Losses: 0.4176\n",
      "Epoch 614/1000, Train Losses: 0.3834, Test Losses: 0.4175\n",
      "Epoch 615/1000, Train Losses: 0.3832, Test Losses: 0.4173\n",
      "Epoch 616/1000, Train Losses: 0.3829, Test Losses: 0.4172\n",
      "Epoch 617/1000, Train Losses: 0.3827, Test Losses: 0.4171\n",
      "Epoch 618/1000, Train Losses: 0.3824, Test Losses: 0.4169\n",
      "Epoch 619/1000, Train Losses: 0.3822, Test Losses: 0.4168\n",
      "Epoch 620/1000, Train Losses: 0.3819, Test Losses: 0.4166\n",
      "Epoch 621/1000, Train Losses: 0.3817, Test Losses: 0.4165\n",
      "Epoch 622/1000, Train Losses: 0.3814, Test Losses: 0.4164\n",
      "Epoch 623/1000, Train Losses: 0.3812, Test Losses: 0.4162\n",
      "Epoch 624/1000, Train Losses: 0.3809, Test Losses: 0.4161\n",
      "Epoch 625/1000, Train Losses: 0.3807, Test Losses: 0.4160\n",
      "Epoch 626/1000, Train Losses: 0.3804, Test Losses: 0.4158\n",
      "Epoch 627/1000, Train Losses: 0.3802, Test Losses: 0.4157\n",
      "Epoch 628/1000, Train Losses: 0.3800, Test Losses: 0.4155\n",
      "Epoch 629/1000, Train Losses: 0.3797, Test Losses: 0.4154\n",
      "Epoch 630/1000, Train Losses: 0.3795, Test Losses: 0.4153\n",
      "Epoch 631/1000, Train Losses: 0.3792, Test Losses: 0.4151\n",
      "Epoch 632/1000, Train Losses: 0.3790, Test Losses: 0.4150\n",
      "Epoch 633/1000, Train Losses: 0.3787, Test Losses: 0.4148\n",
      "Epoch 634/1000, Train Losses: 0.3785, Test Losses: 0.4147\n",
      "Epoch 635/1000, Train Losses: 0.3783, Test Losses: 0.4145\n",
      "Epoch 636/1000, Train Losses: 0.3780, Test Losses: 0.4144\n",
      "Epoch 637/1000, Train Losses: 0.3778, Test Losses: 0.4142\n",
      "Epoch 638/1000, Train Losses: 0.3776, Test Losses: 0.4141\n",
      "Epoch 639/1000, Train Losses: 0.3773, Test Losses: 0.4139\n",
      "Epoch 640/1000, Train Losses: 0.3771, Test Losses: 0.4138\n",
      "Epoch 641/1000, Train Losses: 0.3769, Test Losses: 0.4136\n",
      "Epoch 642/1000, Train Losses: 0.3766, Test Losses: 0.4135\n",
      "Epoch 643/1000, Train Losses: 0.3764, Test Losses: 0.4133\n",
      "Epoch 644/1000, Train Losses: 0.3762, Test Losses: 0.4132\n",
      "Epoch 645/1000, Train Losses: 0.3759, Test Losses: 0.4130\n",
      "Epoch 646/1000, Train Losses: 0.3757, Test Losses: 0.4129\n",
      "Epoch 647/1000, Train Losses: 0.3755, Test Losses: 0.4128\n",
      "Epoch 648/1000, Train Losses: 0.3753, Test Losses: 0.4126\n",
      "Epoch 649/1000, Train Losses: 0.3750, Test Losses: 0.4125\n",
      "Epoch 650/1000, Train Losses: 0.3748, Test Losses: 0.4123\n",
      "Epoch 651/1000, Train Losses: 0.3746, Test Losses: 0.4122\n",
      "Epoch 652/1000, Train Losses: 0.3743, Test Losses: 0.4121\n",
      "Epoch 653/1000, Train Losses: 0.3741, Test Losses: 0.4119\n",
      "Epoch 654/1000, Train Losses: 0.3739, Test Losses: 0.4118\n",
      "Epoch 655/1000, Train Losses: 0.3737, Test Losses: 0.4116\n",
      "Epoch 656/1000, Train Losses: 0.3734, Test Losses: 0.4115\n",
      "Epoch 657/1000, Train Losses: 0.3732, Test Losses: 0.4114\n",
      "Epoch 658/1000, Train Losses: 0.3730, Test Losses: 0.4112\n",
      "Epoch 659/1000, Train Losses: 0.3728, Test Losses: 0.4111\n",
      "Epoch 660/1000, Train Losses: 0.3726, Test Losses: 0.4109\n",
      "Epoch 661/1000, Train Losses: 0.3723, Test Losses: 0.4108\n",
      "Epoch 662/1000, Train Losses: 0.3721, Test Losses: 0.4106\n",
      "Epoch 663/1000, Train Losses: 0.3719, Test Losses: 0.4105\n",
      "Epoch 664/1000, Train Losses: 0.3717, Test Losses: 0.4104\n",
      "Epoch 665/1000, Train Losses: 0.3715, Test Losses: 0.4102\n",
      "Epoch 666/1000, Train Losses: 0.3712, Test Losses: 0.4101\n",
      "Epoch 667/1000, Train Losses: 0.3710, Test Losses: 0.4100\n",
      "Epoch 668/1000, Train Losses: 0.3708, Test Losses: 0.4098\n",
      "Epoch 669/1000, Train Losses: 0.3706, Test Losses: 0.4097\n",
      "Epoch 670/1000, Train Losses: 0.3704, Test Losses: 0.4096\n",
      "Epoch 671/1000, Train Losses: 0.3702, Test Losses: 0.4094\n",
      "Epoch 672/1000, Train Losses: 0.3700, Test Losses: 0.4093\n",
      "Epoch 673/1000, Train Losses: 0.3697, Test Losses: 0.4091\n",
      "Epoch 674/1000, Train Losses: 0.3695, Test Losses: 0.4090\n",
      "Epoch 675/1000, Train Losses: 0.3693, Test Losses: 0.4089\n",
      "Epoch 676/1000, Train Losses: 0.3691, Test Losses: 0.4087\n",
      "Epoch 677/1000, Train Losses: 0.3689, Test Losses: 0.4086\n",
      "Epoch 678/1000, Train Losses: 0.3687, Test Losses: 0.4085\n",
      "Epoch 679/1000, Train Losses: 0.3685, Test Losses: 0.4083\n",
      "Epoch 680/1000, Train Losses: 0.3682, Test Losses: 0.4082\n",
      "Epoch 681/1000, Train Losses: 0.3680, Test Losses: 0.4081\n",
      "Epoch 682/1000, Train Losses: 0.3678, Test Losses: 0.4079\n",
      "Epoch 683/1000, Train Losses: 0.3676, Test Losses: 0.4078\n",
      "Epoch 684/1000, Train Losses: 0.3674, Test Losses: 0.4076\n",
      "Epoch 685/1000, Train Losses: 0.3672, Test Losses: 0.4075\n",
      "Epoch 686/1000, Train Losses: 0.3670, Test Losses: 0.4073\n",
      "Epoch 687/1000, Train Losses: 0.3668, Test Losses: 0.4072\n",
      "Epoch 688/1000, Train Losses: 0.3666, Test Losses: 0.4071\n",
      "Epoch 689/1000, Train Losses: 0.3664, Test Losses: 0.4069\n",
      "Epoch 690/1000, Train Losses: 0.3662, Test Losses: 0.4068\n",
      "Epoch 691/1000, Train Losses: 0.3659, Test Losses: 0.4066\n",
      "Epoch 692/1000, Train Losses: 0.3657, Test Losses: 0.4065\n",
      "Epoch 693/1000, Train Losses: 0.3655, Test Losses: 0.4064\n",
      "Epoch 694/1000, Train Losses: 0.3653, Test Losses: 0.4062\n",
      "Epoch 695/1000, Train Losses: 0.3651, Test Losses: 0.4061\n",
      "Epoch 696/1000, Train Losses: 0.3649, Test Losses: 0.4060\n",
      "Epoch 697/1000, Train Losses: 0.3647, Test Losses: 0.4058\n",
      "Epoch 698/1000, Train Losses: 0.3645, Test Losses: 0.4057\n",
      "Epoch 699/1000, Train Losses: 0.3643, Test Losses: 0.4056\n",
      "Epoch 700/1000, Train Losses: 0.3641, Test Losses: 0.4054\n",
      "Epoch 701/1000, Train Losses: 0.3639, Test Losses: 0.4053\n",
      "Epoch 702/1000, Train Losses: 0.3637, Test Losses: 0.4052\n",
      "Epoch 703/1000, Train Losses: 0.3635, Test Losses: 0.4050\n",
      "Epoch 704/1000, Train Losses: 0.3633, Test Losses: 0.4049\n",
      "Epoch 705/1000, Train Losses: 0.3631, Test Losses: 0.4048\n",
      "Epoch 706/1000, Train Losses: 0.3629, Test Losses: 0.4046\n",
      "Epoch 707/1000, Train Losses: 0.3627, Test Losses: 0.4045\n",
      "Epoch 708/1000, Train Losses: 0.3625, Test Losses: 0.4043\n",
      "Epoch 709/1000, Train Losses: 0.3623, Test Losses: 0.4042\n",
      "Epoch 710/1000, Train Losses: 0.3621, Test Losses: 0.4041\n",
      "Epoch 711/1000, Train Losses: 0.3619, Test Losses: 0.4039\n",
      "Epoch 712/1000, Train Losses: 0.3617, Test Losses: 0.4038\n",
      "Epoch 713/1000, Train Losses: 0.3615, Test Losses: 0.4037\n",
      "Epoch 714/1000, Train Losses: 0.3613, Test Losses: 0.4035\n",
      "Epoch 715/1000, Train Losses: 0.3611, Test Losses: 0.4034\n",
      "Epoch 716/1000, Train Losses: 0.3609, Test Losses: 0.4033\n",
      "Epoch 717/1000, Train Losses: 0.3607, Test Losses: 0.4032\n",
      "Epoch 718/1000, Train Losses: 0.3604, Test Losses: 0.4030\n",
      "Epoch 719/1000, Train Losses: 0.3602, Test Losses: 0.4029\n",
      "Epoch 720/1000, Train Losses: 0.3600, Test Losses: 0.4028\n",
      "Epoch 721/1000, Train Losses: 0.3598, Test Losses: 0.4026\n",
      "Epoch 722/1000, Train Losses: 0.3596, Test Losses: 0.4025\n",
      "Epoch 723/1000, Train Losses: 0.3594, Test Losses: 0.4024\n",
      "Epoch 724/1000, Train Losses: 0.3592, Test Losses: 0.4023\n",
      "Epoch 725/1000, Train Losses: 0.3590, Test Losses: 0.4021\n",
      "Epoch 726/1000, Train Losses: 0.3588, Test Losses: 0.4020\n",
      "Epoch 727/1000, Train Losses: 0.3586, Test Losses: 0.4019\n",
      "Epoch 728/1000, Train Losses: 0.3584, Test Losses: 0.4017\n",
      "Epoch 729/1000, Train Losses: 0.3582, Test Losses: 0.4016\n",
      "Epoch 730/1000, Train Losses: 0.3580, Test Losses: 0.4015\n",
      "Epoch 731/1000, Train Losses: 0.3578, Test Losses: 0.4014\n",
      "Epoch 732/1000, Train Losses: 0.3576, Test Losses: 0.4012\n",
      "Epoch 733/1000, Train Losses: 0.3574, Test Losses: 0.4011\n",
      "Epoch 734/1000, Train Losses: 0.3572, Test Losses: 0.4010\n",
      "Epoch 735/1000, Train Losses: 0.3570, Test Losses: 0.4008\n",
      "Epoch 736/1000, Train Losses: 0.3568, Test Losses: 0.4007\n",
      "Epoch 737/1000, Train Losses: 0.3566, Test Losses: 0.4006\n",
      "Epoch 738/1000, Train Losses: 0.3565, Test Losses: 0.4004\n",
      "Epoch 739/1000, Train Losses: 0.3563, Test Losses: 0.4003\n",
      "Epoch 740/1000, Train Losses: 0.3561, Test Losses: 0.4002\n",
      "Epoch 741/1000, Train Losses: 0.3559, Test Losses: 0.4001\n",
      "Epoch 742/1000, Train Losses: 0.3557, Test Losses: 0.3999\n",
      "Epoch 743/1000, Train Losses: 0.3555, Test Losses: 0.3998\n",
      "Epoch 744/1000, Train Losses: 0.3553, Test Losses: 0.3997\n",
      "Epoch 745/1000, Train Losses: 0.3551, Test Losses: 0.3995\n",
      "Epoch 746/1000, Train Losses: 0.3550, Test Losses: 0.3994\n",
      "Epoch 747/1000, Train Losses: 0.3548, Test Losses: 0.3993\n",
      "Epoch 748/1000, Train Losses: 0.3546, Test Losses: 0.3991\n",
      "Epoch 749/1000, Train Losses: 0.3544, Test Losses: 0.3990\n",
      "Epoch 750/1000, Train Losses: 0.3542, Test Losses: 0.3989\n",
      "Epoch 751/1000, Train Losses: 0.3540, Test Losses: 0.3987\n",
      "Epoch 752/1000, Train Losses: 0.3538, Test Losses: 0.3986\n",
      "Epoch 753/1000, Train Losses: 0.3537, Test Losses: 0.3985\n",
      "Epoch 754/1000, Train Losses: 0.3535, Test Losses: 0.3984\n",
      "Epoch 755/1000, Train Losses: 0.3533, Test Losses: 0.3982\n",
      "Epoch 756/1000, Train Losses: 0.3531, Test Losses: 0.3981\n",
      "Epoch 757/1000, Train Losses: 0.3529, Test Losses: 0.3980\n",
      "Epoch 758/1000, Train Losses: 0.3528, Test Losses: 0.3979\n",
      "Epoch 759/1000, Train Losses: 0.3526, Test Losses: 0.3977\n",
      "Epoch 760/1000, Train Losses: 0.3524, Test Losses: 0.3976\n",
      "Epoch 761/1000, Train Losses: 0.3522, Test Losses: 0.3975\n",
      "Epoch 762/1000, Train Losses: 0.3520, Test Losses: 0.3974\n",
      "Epoch 763/1000, Train Losses: 0.3519, Test Losses: 0.3972\n",
      "Epoch 764/1000, Train Losses: 0.3517, Test Losses: 0.3971\n",
      "Epoch 765/1000, Train Losses: 0.3515, Test Losses: 0.3970\n",
      "Epoch 766/1000, Train Losses: 0.3513, Test Losses: 0.3969\n",
      "Epoch 767/1000, Train Losses: 0.3512, Test Losses: 0.3968\n",
      "Epoch 768/1000, Train Losses: 0.3510, Test Losses: 0.3966\n",
      "Epoch 769/1000, Train Losses: 0.3508, Test Losses: 0.3965\n",
      "Epoch 770/1000, Train Losses: 0.3506, Test Losses: 0.3964\n",
      "Epoch 771/1000, Train Losses: 0.3505, Test Losses: 0.3963\n",
      "Epoch 772/1000, Train Losses: 0.3503, Test Losses: 0.3962\n",
      "Epoch 773/1000, Train Losses: 0.3501, Test Losses: 0.3961\n",
      "Epoch 774/1000, Train Losses: 0.3499, Test Losses: 0.3960\n",
      "Epoch 775/1000, Train Losses: 0.3497, Test Losses: 0.3960\n",
      "Epoch 776/1000, Train Losses: 0.3496, Test Losses: 0.3959\n",
      "Epoch 777/1000, Train Losses: 0.3494, Test Losses: 0.3959\n",
      "Epoch 778/1000, Train Losses: 0.3492, Test Losses: 0.3958\n",
      "Epoch 779/1000, Train Losses: 0.3490, Test Losses: 0.3958\n",
      "Epoch 780/1000, Train Losses: 0.3488, Test Losses: 0.3958\n",
      "Epoch 781/1000, Train Losses: 0.3487, Test Losses: 0.3957\n",
      "Epoch 782/1000, Train Losses: 0.3485, Test Losses: 0.3957\n",
      "Epoch 783/1000, Train Losses: 0.3483, Test Losses: 0.3957\n",
      "Epoch 784/1000, Train Losses: 0.3481, Test Losses: 0.3957\n",
      "Epoch 785/1000, Train Losses: 0.3479, Test Losses: 0.3956\n",
      "Epoch 786/1000, Train Losses: 0.3477, Test Losses: 0.3956\n",
      "Epoch 787/1000, Train Losses: 0.3476, Test Losses: 0.3956\n",
      "Epoch 788/1000, Train Losses: 0.3474, Test Losses: 0.3956\n",
      "Epoch 789/1000, Train Losses: 0.3472, Test Losses: 0.3956\n",
      "Epoch 790/1000, Train Losses: 0.3470, Test Losses: 0.3955\n",
      "Epoch 791/1000, Train Losses: 0.3468, Test Losses: 0.3955\n",
      "Epoch 792/1000, Train Losses: 0.3466, Test Losses: 0.3955\n",
      "Epoch 793/1000, Train Losses: 0.3465, Test Losses: 0.3955\n",
      "Epoch 794/1000, Train Losses: 0.3463, Test Losses: 0.3955\n",
      "Epoch 795/1000, Train Losses: 0.3461, Test Losses: 0.3954\n",
      "Epoch 796/1000, Train Losses: 0.3459, Test Losses: 0.3954\n",
      "Epoch 797/1000, Train Losses: 0.3457, Test Losses: 0.3954\n",
      "Epoch 798/1000, Train Losses: 0.3455, Test Losses: 0.3953\n",
      "Epoch 799/1000, Train Losses: 0.3454, Test Losses: 0.3953\n",
      "Epoch 800/1000, Train Losses: 0.3452, Test Losses: 0.3952\n",
      "Epoch 801/1000, Train Losses: 0.3450, Test Losses: 0.3952\n",
      "Epoch 802/1000, Train Losses: 0.3448, Test Losses: 0.3951\n",
      "Epoch 803/1000, Train Losses: 0.3447, Test Losses: 0.3951\n",
      "Epoch 804/1000, Train Losses: 0.3445, Test Losses: 0.3950\n",
      "Epoch 805/1000, Train Losses: 0.3443, Test Losses: 0.3950\n",
      "Epoch 806/1000, Train Losses: 0.3441, Test Losses: 0.3949\n",
      "Epoch 807/1000, Train Losses: 0.3439, Test Losses: 0.3949\n",
      "Epoch 808/1000, Train Losses: 0.3438, Test Losses: 0.3948\n",
      "Epoch 809/1000, Train Losses: 0.3436, Test Losses: 0.3948\n",
      "Epoch 810/1000, Train Losses: 0.3434, Test Losses: 0.3947\n",
      "Epoch 811/1000, Train Losses: 0.3432, Test Losses: 0.3947\n",
      "Epoch 812/1000, Train Losses: 0.3430, Test Losses: 0.3946\n",
      "Epoch 813/1000, Train Losses: 0.3429, Test Losses: 0.3946\n",
      "Epoch 814/1000, Train Losses: 0.3427, Test Losses: 0.3945\n",
      "Epoch 815/1000, Train Losses: 0.3425, Test Losses: 0.3945\n",
      "Epoch 816/1000, Train Losses: 0.3423, Test Losses: 0.3945\n",
      "Epoch 817/1000, Train Losses: 0.3421, Test Losses: 0.3944\n",
      "Epoch 818/1000, Train Losses: 0.3420, Test Losses: 0.3943\n",
      "Epoch 819/1000, Train Losses: 0.3418, Test Losses: 0.3943\n",
      "Epoch 820/1000, Train Losses: 0.3416, Test Losses: 0.3942\n",
      "Epoch 821/1000, Train Losses: 0.3414, Test Losses: 0.3942\n",
      "Epoch 822/1000, Train Losses: 0.3413, Test Losses: 0.3941\n",
      "Epoch 823/1000, Train Losses: 0.3411, Test Losses: 0.3940\n",
      "Epoch 824/1000, Train Losses: 0.3409, Test Losses: 0.3940\n",
      "Epoch 825/1000, Train Losses: 0.3407, Test Losses: 0.3939\n",
      "Epoch 826/1000, Train Losses: 0.3405, Test Losses: 0.3939\n",
      "Epoch 827/1000, Train Losses: 0.3404, Test Losses: 0.3939\n",
      "Epoch 828/1000, Train Losses: 0.3402, Test Losses: 0.3938\n",
      "Epoch 829/1000, Train Losses: 0.3400, Test Losses: 0.3938\n",
      "Epoch 830/1000, Train Losses: 0.3398, Test Losses: 0.3938\n",
      "Epoch 831/1000, Train Losses: 0.3396, Test Losses: 0.3938\n",
      "Epoch 832/1000, Train Losses: 0.3394, Test Losses: 0.3938\n",
      "Epoch 833/1000, Train Losses: 0.3393, Test Losses: 0.3938\n",
      "Epoch 834/1000, Train Losses: 0.3391, Test Losses: 0.3938\n",
      "Epoch 835/1000, Train Losses: 0.3389, Test Losses: 0.3938\n",
      "Epoch 836/1000, Train Losses: 0.3387, Test Losses: 0.3938\n",
      "Epoch 837/1000, Train Losses: 0.3385, Test Losses: 0.3938\n",
      "Epoch 838/1000, Train Losses: 0.3384, Test Losses: 0.3938\n",
      "Epoch 839/1000, Train Losses: 0.3382, Test Losses: 0.3937\n",
      "Epoch 840/1000, Train Losses: 0.3380, Test Losses: 0.3937\n",
      "Epoch 841/1000, Train Losses: 0.3378, Test Losses: 0.3937\n",
      "Epoch 842/1000, Train Losses: 0.3376, Test Losses: 0.3936\n",
      "Epoch 843/1000, Train Losses: 0.3375, Test Losses: 0.3936\n",
      "Epoch 844/1000, Train Losses: 0.3373, Test Losses: 0.3935\n",
      "Epoch 845/1000, Train Losses: 0.3371, Test Losses: 0.3935\n",
      "Epoch 846/1000, Train Losses: 0.3369, Test Losses: 0.3934\n",
      "Epoch 847/1000, Train Losses: 0.3368, Test Losses: 0.3934\n",
      "Epoch 848/1000, Train Losses: 0.3366, Test Losses: 0.3933\n",
      "Epoch 849/1000, Train Losses: 0.3364, Test Losses: 0.3932\n",
      "Epoch 850/1000, Train Losses: 0.3362, Test Losses: 0.3932\n",
      "Epoch 851/1000, Train Losses: 0.3361, Test Losses: 0.3931\n",
      "Epoch 852/1000, Train Losses: 0.3359, Test Losses: 0.3930\n",
      "Epoch 853/1000, Train Losses: 0.3357, Test Losses: 0.3930\n",
      "Epoch 854/1000, Train Losses: 0.3355, Test Losses: 0.3929\n",
      "Epoch 855/1000, Train Losses: 0.3354, Test Losses: 0.3928\n",
      "Epoch 856/1000, Train Losses: 0.3352, Test Losses: 0.3927\n",
      "Epoch 857/1000, Train Losses: 0.3350, Test Losses: 0.3926\n",
      "Epoch 858/1000, Train Losses: 0.3348, Test Losses: 0.3925\n",
      "Epoch 859/1000, Train Losses: 0.3347, Test Losses: 0.3924\n",
      "Epoch 860/1000, Train Losses: 0.3345, Test Losses: 0.3924\n",
      "Epoch 861/1000, Train Losses: 0.3344, Test Losses: 0.3923\n",
      "Epoch 862/1000, Train Losses: 0.3342, Test Losses: 0.3922\n",
      "Epoch 863/1000, Train Losses: 0.3340, Test Losses: 0.3921\n",
      "Epoch 864/1000, Train Losses: 0.3339, Test Losses: 0.3920\n",
      "Epoch 865/1000, Train Losses: 0.3337, Test Losses: 0.3919\n",
      "Epoch 866/1000, Train Losses: 0.3335, Test Losses: 0.3918\n",
      "Epoch 867/1000, Train Losses: 0.3334, Test Losses: 0.3917\n",
      "Epoch 868/1000, Train Losses: 0.3332, Test Losses: 0.3917\n",
      "Epoch 869/1000, Train Losses: 0.3331, Test Losses: 0.3916\n",
      "Epoch 870/1000, Train Losses: 0.3329, Test Losses: 0.3915\n",
      "Epoch 871/1000, Train Losses: 0.3327, Test Losses: 0.3914\n",
      "Epoch 872/1000, Train Losses: 0.3326, Test Losses: 0.3913\n",
      "Epoch 873/1000, Train Losses: 0.3324, Test Losses: 0.3912\n",
      "Epoch 874/1000, Train Losses: 0.3323, Test Losses: 0.3911\n",
      "Epoch 875/1000, Train Losses: 0.3321, Test Losses: 0.3911\n",
      "Epoch 876/1000, Train Losses: 0.3320, Test Losses: 0.3910\n",
      "Epoch 877/1000, Train Losses: 0.3318, Test Losses: 0.3909\n",
      "Epoch 878/1000, Train Losses: 0.3316, Test Losses: 0.3908\n",
      "Epoch 879/1000, Train Losses: 0.3315, Test Losses: 0.3907\n",
      "Epoch 880/1000, Train Losses: 0.3313, Test Losses: 0.3907\n",
      "Epoch 881/1000, Train Losses: 0.3312, Test Losses: 0.3906\n",
      "Epoch 882/1000, Train Losses: 0.3310, Test Losses: 0.3905\n",
      "Epoch 883/1000, Train Losses: 0.3309, Test Losses: 0.3905\n",
      "Epoch 884/1000, Train Losses: 0.3307, Test Losses: 0.3904\n",
      "Epoch 885/1000, Train Losses: 0.3305, Test Losses: 0.3903\n",
      "Epoch 886/1000, Train Losses: 0.3304, Test Losses: 0.3902\n",
      "Epoch 887/1000, Train Losses: 0.3302, Test Losses: 0.3902\n",
      "Epoch 888/1000, Train Losses: 0.3301, Test Losses: 0.3901\n",
      "Epoch 889/1000, Train Losses: 0.3299, Test Losses: 0.3900\n",
      "Epoch 890/1000, Train Losses: 0.3297, Test Losses: 0.3900\n",
      "Epoch 891/1000, Train Losses: 0.3296, Test Losses: 0.3899\n",
      "Epoch 892/1000, Train Losses: 0.3294, Test Losses: 0.3899\n",
      "Epoch 893/1000, Train Losses: 0.3292, Test Losses: 0.3899\n",
      "Epoch 894/1000, Train Losses: 0.3291, Test Losses: 0.3898\n",
      "Epoch 895/1000, Train Losses: 0.3289, Test Losses: 0.3898\n",
      "Epoch 896/1000, Train Losses: 0.3287, Test Losses: 0.3897\n",
      "Epoch 897/1000, Train Losses: 0.3286, Test Losses: 0.3897\n",
      "Epoch 898/1000, Train Losses: 0.3284, Test Losses: 0.3897\n",
      "Epoch 899/1000, Train Losses: 0.3282, Test Losses: 0.3896\n",
      "Epoch 900/1000, Train Losses: 0.3281, Test Losses: 0.3895\n",
      "Epoch 901/1000, Train Losses: 0.3279, Test Losses: 0.3895\n",
      "Epoch 902/1000, Train Losses: 0.3278, Test Losses: 0.3894\n",
      "Epoch 903/1000, Train Losses: 0.3276, Test Losses: 0.3893\n",
      "Epoch 904/1000, Train Losses: 0.3275, Test Losses: 0.3892\n",
      "Epoch 905/1000, Train Losses: 0.3273, Test Losses: 0.3891\n",
      "Epoch 906/1000, Train Losses: 0.3272, Test Losses: 0.3890\n",
      "Epoch 907/1000, Train Losses: 0.3270, Test Losses: 0.3889\n",
      "Epoch 908/1000, Train Losses: 0.3269, Test Losses: 0.3888\n",
      "Epoch 909/1000, Train Losses: 0.3267, Test Losses: 0.3887\n",
      "Epoch 910/1000, Train Losses: 0.3266, Test Losses: 0.3886\n",
      "Epoch 911/1000, Train Losses: 0.3264, Test Losses: 0.3885\n",
      "Epoch 912/1000, Train Losses: 0.3263, Test Losses: 0.3884\n",
      "Epoch 913/1000, Train Losses: 0.3261, Test Losses: 0.3883\n",
      "Epoch 914/1000, Train Losses: 0.3260, Test Losses: 0.3882\n",
      "Epoch 915/1000, Train Losses: 0.3258, Test Losses: 0.3881\n",
      "Epoch 916/1000, Train Losses: 0.3257, Test Losses: 0.3880\n",
      "Epoch 917/1000, Train Losses: 0.3255, Test Losses: 0.3879\n",
      "Epoch 918/1000, Train Losses: 0.3254, Test Losses: 0.3878\n",
      "Epoch 919/1000, Train Losses: 0.3252, Test Losses: 0.3877\n",
      "Epoch 920/1000, Train Losses: 0.3251, Test Losses: 0.3876\n",
      "Epoch 921/1000, Train Losses: 0.3249, Test Losses: 0.3875\n",
      "Epoch 922/1000, Train Losses: 0.3248, Test Losses: 0.3874\n",
      "Epoch 923/1000, Train Losses: 0.3246, Test Losses: 0.3873\n",
      "Epoch 924/1000, Train Losses: 0.3245, Test Losses: 0.3872\n",
      "Epoch 925/1000, Train Losses: 0.3244, Test Losses: 0.3871\n",
      "Epoch 926/1000, Train Losses: 0.3242, Test Losses: 0.3870\n",
      "Epoch 927/1000, Train Losses: 0.3241, Test Losses: 0.3869\n",
      "Epoch 928/1000, Train Losses: 0.3239, Test Losses: 0.3868\n",
      "Epoch 929/1000, Train Losses: 0.3238, Test Losses: 0.3868\n",
      "Epoch 930/1000, Train Losses: 0.3236, Test Losses: 0.3867\n",
      "Epoch 931/1000, Train Losses: 0.3235, Test Losses: 0.3866\n",
      "Epoch 932/1000, Train Losses: 0.3234, Test Losses: 0.3865\n",
      "Epoch 933/1000, Train Losses: 0.3232, Test Losses: 0.3864\n",
      "Epoch 934/1000, Train Losses: 0.3231, Test Losses: 0.3863\n",
      "Epoch 935/1000, Train Losses: 0.3229, Test Losses: 0.3862\n",
      "Epoch 936/1000, Train Losses: 0.3228, Test Losses: 0.3861\n",
      "Epoch 937/1000, Train Losses: 0.3227, Test Losses: 0.3861\n",
      "Epoch 938/1000, Train Losses: 0.3225, Test Losses: 0.3860\n",
      "Epoch 939/1000, Train Losses: 0.3224, Test Losses: 0.3859\n",
      "Epoch 940/1000, Train Losses: 0.3222, Test Losses: 0.3858\n",
      "Epoch 941/1000, Train Losses: 0.3221, Test Losses: 0.3857\n",
      "Epoch 942/1000, Train Losses: 0.3220, Test Losses: 0.3857\n",
      "Epoch 943/1000, Train Losses: 0.3218, Test Losses: 0.3856\n",
      "Epoch 944/1000, Train Losses: 0.3217, Test Losses: 0.3855\n",
      "Epoch 945/1000, Train Losses: 0.3216, Test Losses: 0.3854\n",
      "Epoch 946/1000, Train Losses: 0.3214, Test Losses: 0.3854\n",
      "Epoch 947/1000, Train Losses: 0.3213, Test Losses: 0.3853\n",
      "Epoch 948/1000, Train Losses: 0.3211, Test Losses: 0.3852\n",
      "Epoch 949/1000, Train Losses: 0.3210, Test Losses: 0.3852\n",
      "Epoch 950/1000, Train Losses: 0.3209, Test Losses: 0.3851\n",
      "Epoch 951/1000, Train Losses: 0.3207, Test Losses: 0.3850\n",
      "Epoch 952/1000, Train Losses: 0.3206, Test Losses: 0.3849\n",
      "Epoch 953/1000, Train Losses: 0.3205, Test Losses: 0.3849\n",
      "Epoch 954/1000, Train Losses: 0.3203, Test Losses: 0.3848\n",
      "Epoch 955/1000, Train Losses: 0.3202, Test Losses: 0.3847\n",
      "Epoch 956/1000, Train Losses: 0.3201, Test Losses: 0.3846\n",
      "Epoch 957/1000, Train Losses: 0.3199, Test Losses: 0.3846\n",
      "Epoch 958/1000, Train Losses: 0.3198, Test Losses: 0.3845\n",
      "Epoch 959/1000, Train Losses: 0.3197, Test Losses: 0.3844\n",
      "Epoch 960/1000, Train Losses: 0.3195, Test Losses: 0.3844\n",
      "Epoch 961/1000, Train Losses: 0.3194, Test Losses: 0.3843\n",
      "Epoch 962/1000, Train Losses: 0.3193, Test Losses: 0.3842\n",
      "Epoch 963/1000, Train Losses: 0.3191, Test Losses: 0.3842\n",
      "Epoch 964/1000, Train Losses: 0.3190, Test Losses: 0.3841\n",
      "Epoch 965/1000, Train Losses: 0.3189, Test Losses: 0.3840\n",
      "Epoch 966/1000, Train Losses: 0.3187, Test Losses: 0.3839\n",
      "Epoch 967/1000, Train Losses: 0.3186, Test Losses: 0.3839\n",
      "Epoch 968/1000, Train Losses: 0.3185, Test Losses: 0.3838\n",
      "Epoch 969/1000, Train Losses: 0.3183, Test Losses: 0.3837\n",
      "Epoch 970/1000, Train Losses: 0.3182, Test Losses: 0.3837\n",
      "Epoch 971/1000, Train Losses: 0.3181, Test Losses: 0.3836\n",
      "Epoch 972/1000, Train Losses: 0.3180, Test Losses: 0.3835\n",
      "Epoch 973/1000, Train Losses: 0.3178, Test Losses: 0.3834\n",
      "Epoch 974/1000, Train Losses: 0.3177, Test Losses: 0.3834\n",
      "Epoch 975/1000, Train Losses: 0.3176, Test Losses: 0.3833\n",
      "Epoch 976/1000, Train Losses: 0.3174, Test Losses: 0.3833\n",
      "Epoch 977/1000, Train Losses: 0.3173, Test Losses: 0.3832\n",
      "Epoch 978/1000, Train Losses: 0.3172, Test Losses: 0.3832\n",
      "Epoch 979/1000, Train Losses: 0.3171, Test Losses: 0.3831\n",
      "Epoch 980/1000, Train Losses: 0.3169, Test Losses: 0.3831\n",
      "Epoch 981/1000, Train Losses: 0.3168, Test Losses: 0.3831\n",
      "Epoch 982/1000, Train Losses: 0.3167, Test Losses: 0.3831\n",
      "Epoch 983/1000, Train Losses: 0.3166, Test Losses: 0.3831\n",
      "Epoch 984/1000, Train Losses: 0.3164, Test Losses: 0.3830\n",
      "Epoch 985/1000, Train Losses: 0.3163, Test Losses: 0.3830\n",
      "Epoch 986/1000, Train Losses: 0.3162, Test Losses: 0.3830\n",
      "Epoch 987/1000, Train Losses: 0.3160, Test Losses: 0.3829\n",
      "Epoch 988/1000, Train Losses: 0.3159, Test Losses: 0.3829\n",
      "Epoch 989/1000, Train Losses: 0.3158, Test Losses: 0.3828\n",
      "Epoch 990/1000, Train Losses: 0.3157, Test Losses: 0.3828\n",
      "Epoch 991/1000, Train Losses: 0.3155, Test Losses: 0.3827\n",
      "Epoch 992/1000, Train Losses: 0.3154, Test Losses: 0.3827\n",
      "Epoch 993/1000, Train Losses: 0.3153, Test Losses: 0.3827\n",
      "Epoch 994/1000, Train Losses: 0.3152, Test Losses: 0.3826\n",
      "Epoch 995/1000, Train Losses: 0.3150, Test Losses: 0.3826\n",
      "Epoch 996/1000, Train Losses: 0.3149, Test Losses: 0.3826\n",
      "Epoch 997/1000, Train Losses: 0.3148, Test Losses: 0.3825\n",
      "Epoch 998/1000, Train Losses: 0.3147, Test Losses: 0.3825\n",
      "Epoch 999/1000, Train Losses: 0.3145, Test Losses: 0.3825\n",
      "Epoch 1000/1000, Train Losses: 0.3144, Test Losses: 0.3824\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for it in range(n_epochs):\n",
    "  optimizer.zero_grad()\n",
    "  outputs = model(inputs)\n",
    "  loss = criterion(outputs, targets)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_losses.append(loss.item())\n",
    "\n",
    "  out_test = model(inputs_test)\n",
    "  loss_test = criterion(out_test, targets_test)\n",
    "  loss_test.backward()\n",
    "  test_losses.append(loss_test.item())\n",
    "  print(f'Epoch {it+1}/{n_epochs}, Train Losses: {loss.item():.4f}, Test Losses: {loss_test.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train_losses')\n",
    "plt.plot(test_losses, label='test_losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660714285714286\n",
      "0.8738738738738738\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "n_total = 0\n",
    "_, targetsIndex = torch.max(targets, 1)\n",
    "outputs = model(inputs)\n",
    "_, predictions = torch.max(outputs,1)\n",
    "n_correct += (predictions == targetsIndex).sum().item()\n",
    "n_total += targetsIndex.shape[0]\n",
    "\n",
    "train_acc = n_correct/n_total\n",
    "print(train_acc)\n",
    "\n",
    "n_correct = 0\n",
    "n_total = 0\n",
    "_, targetsIndex = torch.max(targets_test, 1)\n",
    "outputs = model(inputs_test)\n",
    "_, predictions = torch.max(outputs,1)\n",
    "n_correct += (predictions == targetsIndex).sum().item()\n",
    "n_total += targetsIndex.shape[0]\n",
    "\n",
    "test_acc = n_correct/n_total\n",
    "print(test_acc)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
