{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I will apply linear regression to analyse the boston housing price, and a way to predict the price based on the parameters given by the dataset in \"boston.txt\". To achieve this I used linear regression model with SGD optimization and mean square error loss function. All methods provided by the Pytorch engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieving data\n",
    "ls = [item for item in range(7, 22)]\n",
    "file1 = open('boston.txt', 'r')\n",
    "head = []\n",
    "for i, line in enumerate(file1):\n",
    "  try:\n",
    "    if i in ls:\n",
    "      head.append(line.strip().split()[0])\n",
    "  except:\n",
    "    break\n",
    "data = pd.read_table(\"boston.txt\", skiprows = 22, sep='\\s+', engine=\"python\", header=None)\n",
    "data = data.to_numpy()\n",
    "data = np.reshape(data,(506,22))\n",
    "data = data[0:,:14].astype(np.float32)\n",
    "\n",
    "#Shuffle the rows from data so I could take arbitrary rows for test and training.\n",
    "rd.shuffle(data) \n",
    "pivo = round(data.shape[0]*0.66)\n",
    "train = data[0:pivo, :]\n",
    "test = data[pivo+1:data.shape[0], :]\n",
    "\n",
    "#training data manipulation\n",
    "X = train[0:,:13]\n",
    "Y = train[0:,13:]\n",
    "Xm = np.mean(X, axis = 0)\n",
    "Ym = np.mean(Y, axis = 0)\n",
    "Xs = np.std(X, axis = 0)\n",
    "Ys = np.std(Y, axis = 0)\n",
    "im = (X-Xm)/Xs\n",
    "out = (Y-Ym)/Ys\n",
    "\n",
    "#test data manpulation\n",
    "Tx = test[0:,:13]\n",
    "Ty = test[0:,13:]\n",
    "testX = (Tx - np.mean(Tx, axis=0))/np.std(Tx, axis=0)\n",
    "testY = (Ty - np.mean(Ty, axis=0))/np.std(Ty, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating linear regression model\n",
    "model = nn.Linear(13,1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 0.01, momentum=0.7)\n",
    "inputs = torch.from_numpy(im)\n",
    "targets = torch.from_numpy(out)\n",
    "\n",
    "#test data\n",
    "tstX = torch.from_numpy(testX)\n",
    "tstY = torch.from_numpy(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 1.0289, Test Loss: 0.9161\n",
      "Epoch 51/1000, Loss: 0.3127, Test Loss: 0.2354\n",
      "Epoch 101/1000, Loss: 0.2905, Test Loss: 0.2237\n",
      "Epoch 151/1000, Loss: 0.2839, Test Loss: 0.2223\n",
      "Epoch 201/1000, Loss: 0.2815, Test Loss: 0.2227\n",
      "Epoch 251/1000, Loss: 0.2806, Test Loss: 0.2231\n",
      "Epoch 301/1000, Loss: 0.2802, Test Loss: 0.2234\n",
      "Epoch 351/1000, Loss: 0.2800, Test Loss: 0.2235\n",
      "Epoch 401/1000, Loss: 0.2799, Test Loss: 0.2235\n",
      "Epoch 451/1000, Loss: 0.2798, Test Loss: 0.2235\n",
      "Epoch 501/1000, Loss: 0.2797, Test Loss: 0.2235\n",
      "Epoch 551/1000, Loss: 0.2797, Test Loss: 0.2235\n",
      "Epoch 601/1000, Loss: 0.2797, Test Loss: 0.2234\n",
      "Epoch 651/1000, Loss: 0.2797, Test Loss: 0.2234\n",
      "Epoch 701/1000, Loss: 0.2797, Test Loss: 0.2234\n",
      "Epoch 751/1000, Loss: 0.2797, Test Loss: 0.2233\n",
      "Epoch 801/1000, Loss: 0.2797, Test Loss: 0.2233\n",
      "Epoch 851/1000, Loss: 0.2797, Test Loss: 0.2233\n",
      "Epoch 901/1000, Loss: 0.2797, Test Loss: 0.2233\n",
      "Epoch 951/1000, Loss: 0.2797, Test Loss: 0.2233\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "n_epochs = 1000\n",
    "losses = []\n",
    "train_losses = []\n",
    "\n",
    "for it in range(n_epochs):\n",
    "  optimizer.zero_grad()\n",
    "  outputs = model(inputs)\n",
    "  loss = criterion(outputs,targets)\n",
    "  losses.append(loss.item())\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  #test loss\n",
    "  outputs_test = model(tstX)\n",
    "  loss_test = criterion(outputs_test, tstY)\n",
    "  train_losses.append(loss_test.item())\n",
    "  if(it % 50 == 0):\n",
    "    print(f'Epoch {it+1}/{n_epochs}, Loss: {loss.item():.4f}, Test Loss: {loss_test.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Coeficient from bias calculated by pytorch: [45.752327]\n",
      "Linear Coeficient calculating the mean between the differences (model x targets): 45.75232696533203\n",
      "Weights or angular coeficients:\n",
      " CRIM,ZN,INDUS,CHAS,NOX,RM,AGE,DIS,RAD,TAX,PTRATIO,B,LSTAT,\n",
      " [-1.19010441e-01  4.46854904e-02 -3.26025896e-02  2.83967948e+00\n",
      " -1.72440128e+01  2.93075919e+00 -1.20709585e-02 -1.85048485e+00\n",
      "  2.92700738e-01 -1.17064910e-02 -1.03114569e+00  9.29468311e-03\n",
      " -5.12081861e-01]\n"
     ]
    }
   ],
   "source": [
    "w = model.weight.data.numpy()\n",
    "v = model.bias.data.numpy()\n",
    "a = w*Ys/Xs\n",
    "a = a[0]\n",
    "values = np.dot(X, a.T)\n",
    "b = np.mean(Y-values)\n",
    "b_other = Ym - np.sum((Ys*Xm*w)/Xs, axis=1) + v*Ys\n",
    "head.pop()\n",
    "str_head = ''.join(f'{str(e)},' for e in head)\n",
    "\n",
    "#b calculated from bias in pytorch with SGD optim exactly the same as the mean diference\n",
    "print(f'Linear Coeficient from bias calculated by pytorch: {b_other}')\n",
    "print(f'Linear Coeficient calculating the mean between the differences (model x targets): {b}')\n",
    "print(f'Weights or angular coeficients:\\n {str_head}\\n {a}')\n",
    "savevals = np.append(a,b_other, axis=0).reshape(1,14)\n",
    "str_head += 'b'\n",
    "np.savetxt('boston_housing_price_prediction.csv', savevals, delimiter=',', comments='#Weights for all variables and bias (b)\\n', header= str_head)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
